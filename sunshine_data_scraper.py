from selenium.common.exceptions import NoSuchElementExceptionfrom selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.chrome.service import Servicefrom webdriver_manager.chrome import ChromeDriverManagerimport timeimport pandas as pdimport csvsave_to_path = '/Users/svetlanamaslenkova/Documents/Ghamut_project/data/'url = 'https://www.currentresults.com/Weather/US/average-annual-state-sunshine.php'## Initializing the webdriveroptions = webdriver.ChromeOptions()driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))driver.set_window_size(1120, 1000)def get_data(driver=driver, url=url, verbose=True, slp_time=2):        driver.get(url)    time.sleep(1)        rows = driver.find_elements(        By.XPATH, '//*[@id="maincol"]/div[1]/table//tr')    print('number of rows: ', len(rows))            collected_successfully = False    data = []    while not collected_successfully:        try:            for row in rows:                row_data = [item.text for item in row.find_elements(By.XPATH, ".//*[self::td]")]                if len(row_data)>0:                    data.append(row_data)                    print(data)                        collected_successfully = True        except:            time.sleep(5)            return datadata = get_data()header = ['State', 'Place', '% Sun', 'Total Hours', 'Clear Days']data_to_csv = [*[header], *data]with open(save_to_path+'sunshine_data.csv', "w", newline="") as f:    writer = csv.writer(f)    writer.writerows(data_to_csv)