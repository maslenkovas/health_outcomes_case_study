{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08cbeead-e774-4188-9568-f293eeeb6b79",
   "metadata": {
    "id": "08cbeead-e774-4188-9568-f293eeeb6b79"
   },
   "source": [
    "# USA Health Outcomes study\n",
    "\n",
    "<span style=\"color:red\"> Svetlana Maslenkova </span>\n",
    "\n",
    "## Goal of the project\n",
    "For this case study, you will perform a series of analyses to clarify the factors associated with population health outcomes in the United States. More specifically, the goal of your analysis is to understand how the health outcomes of US counties are associated with the county's characteristics: demographic, geographic, economic, behavioral, etc.   \n",
    "\n",
    "## Data\n",
    "All analysis for this case study will use the [PLACES Dataset](https://chronicdata.cdc.gov/500-Cities-Places/PLACES-County-Data-GIS-Friendly-Format-2022-releas/i46a-9kgh). The PLACES dataset contains information on the prevalence of health conditions across US counties. Some of the database columns contain information about general health (e.g. `GHLTH_CrudePrev` describe the prevalence of general health issues) while other columns refer to specific health conditions (e.g. `DEPRESSION_CrudePrev` describes the prevalence of depression). In addition to that, other datasets supplement the data from PLACES with additional information to help in answering the questions herein (e.g. data from the US Census, CDC, etc.).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2c646e-d1fd-4396-9a17-3834d4c7f04a",
   "metadata": {
    "id": "be2c646e-d1fd-4396-9a17-3834d4c7f04a"
   },
   "source": [
    "## 1. Data Task \n",
    "\n",
    "Study the data described in `Section 0.4`; then select one or more publically available datasets that provide characteristics of US counties that you think will be associated with the health outcomes reported in the PLACES Dataset; be prepared to justify your dataset selection. Merge your selected datasets with the data from the PLACES Dataset into a single DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6PNJt9XLT7b9",
   "metadata": {
    "id": "6PNJt9XLT7b9"
   },
   "source": [
    "### Cells for working on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-VteuUIXO9Gz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VteuUIXO9Gz",
    "outputId": "8c0114ff-6e71-455c-8b99-efb5a03afa1d"
   },
   "outputs": [],
   "source": [
    "# # # for google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # define the path to data\n",
    "# data_path = '/content/drive/MyDrive/Colab_Notebooks/Ghamut_assessment/data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "rQQhz6c-UBMA",
   "metadata": {
    "id": "rQQhz6c-UBMA"
   },
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.getcwd() + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rrueYOSsPOwY",
   "metadata": {
    "id": "rrueYOSsPOwY"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# loading PLACES data by county\n",
    "places_data = pd.read_csv(data_path+'PLACES__County_Data__GIS_Friendly_Format___2022_release.csv')\n",
    "places_data.columns = places_data.columns.str.lower()\n",
    "\n",
    "# loading demographics data by county\n",
    "demographics_data = pd.read_csv(data_path+'cc-est2021-all.csv', encoding='latin-1')\n",
    "demographics_data = demographics_data[demographics_data.YEAR==1]\n",
    "demographics_data.columns = demographics_data.columns.str.lower()\n",
    "# get sample for a preview\n",
    "sample_demo_data = demographics_data.iloc[10, :]\n",
    "\n",
    "# loading poverty data by county\n",
    "poverty_data = pd.read_excel(data_path+'PovertyEstimates.xlsx', header=4) \n",
    "poverty_data.columns = poverty_data.columns.str.lower()\n",
    "\n",
    "# loading unemployment data by county\n",
    "unemployment_data = pd.read_excel(data_path+'Unemployment.xlsx', header=4, usecols=\"A:F,CJ:CR\") \n",
    "unemployment_data.columns = unemployment_data.columns.str.lower()\n",
    "\n",
    "# loading education data by county\n",
    "education_data = pd.read_excel(data_path+'Education.xlsx', header=3, usecols=\"A:C,F,G,AV:BC\") \n",
    "education_data.columns = education_data.columns.str.lower()\n",
    "\n",
    "# loading social vulnerability data by county\n",
    "svi_data = pd.read_csv(data_path+'Social_Vulnerability_Index_2018_-__United_States__county.csv')\n",
    "svi_data.columns = svi_data.columns.str.lower()\n",
    "\n",
    "# loading mortality data by county\n",
    "with  open(data_path+'Multiple Cause of Death, 2018-2021, Single Race.txt', 'r') as f:\n",
    "    lines = [line.replace('\\n', '').split('\\t') for line in f.readlines()]\n",
    "mort_data = pd.DataFrame(lines[1:], columns=lines[0])\n",
    "mort_data.columns = mort_data.columns.str.lower().str.replace('\"', '')\n",
    "mort_data = mort_data.iloc[:3114, :]\n",
    "\n",
    "# loading sunshine data by state\n",
    "sunshine_data = pd.read_csv(data_path+'sunshine_data.csv')\n",
    "sunshine_data.columns = sunshine_data.columns.str.lower()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "-1JCBckY3mx3",
   "metadata": {
    "id": "-1JCBckY3mx3"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28c055-1cd5-45fa-b8ee-ca8070fa7b15",
   "metadata": {
    "id": "1d28c055-1cd5-45fa-b8ee-ca8070fa7b15"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# remove some columns from PLACES and keep only crude prevalence ones\n",
    "data_pl = places_data.loc[:, ~(places_data.columns.str.contains('95ci|adjprev'))]\n",
    "\n",
    "## demographics data\n",
    "demographics_columns = ['STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'AGEGRP', 'TOT_POP', 'TOT_MALE', 'TOT_FEMALE', 'WA_MALE', 'WA_FEMALE', 'BA_MALE', 'BA_FEMALE', 'IA_MALE', 'IA_FEMALE', 'AA_MALE', 'AA_FEMALE', 'NA_MALE', 'NA_FEMALE', 'TOM_MALE', 'TOM_FEMALE'] \n",
    "# sum female and male populations by race\n",
    "WA = demographics_data.wa_male + demographics_data.wa_female\n",
    "BA = demographics_data.ba_male + demographics_data.ba_female\n",
    "IA = demographics_data.ia_male + demographics_data.ia_female\n",
    "AA = demographics_data.aa_male + demographics_data.aa_female\n",
    "NA = demographics_data.na_male + demographics_data.na_female\n",
    "TOM = demographics_data.tom_male + demographics_data.tom_female\n",
    "# get new dataframe for demographics with only necessary columns\n",
    "demo_data = demographics_data[['state', 'county', 'stname', 'ctyname', 'agegrp', 'tot_pop', 'tot_male', 'tot_female']]\n",
    "demo_data.loc[:, 'race_wa'] = WA\n",
    "demo_data.loc[:, 'race_ba'] = BA\n",
    "demo_data.loc[:, 'race_ia'] = IA\n",
    "demo_data.loc[:, 'race_aa'] = AA\n",
    "demo_data.loc[:, 'race_na'] = NA\n",
    "demo_data.loc[:, 'race_tom'] = TOM\n",
    "# rename gender columns \n",
    "demo_data = demo_data.rename(columns={'tot_male':'male', 'tot_female':'female', 'tot_pop':'population'})\n",
    "# map age groups to a smaller set\n",
    "demo_data.agegrp = demo_data.agegrp.apply(lambda x: 'agegrp_1' if x in range(1,5) else 'agegrp_2' if x in range(5,9) else 'agegrp_3' if x in range(9,14) else 'agegrp_4' if x in range(14,19) else 'agegrp_tot')\n",
    "# get population by race, gender and age group (for EDA)\n",
    "population_by_race_gender_agegroup = pd.pivot_table(demo_data, index=['state', 'county'], columns=['agegrp'], aggfunc='sum')\n",
    "population_by_race_gender_agegroup.columns = ['{}_{}'.format(t, v) for v,t in population_by_race_gender_agegroup.columns]\n",
    "population_by_race_gender_agegroup = population_by_race_gender_agegroup.reset_index()\n",
    "# get population by age groups \n",
    "population_by_age = demo_data[~(demo_data.agegrp=='agegrp_tot')].groupby(['state', 'county', 'agegrp']).agg('sum')['population'].reset_index()\n",
    "population_by_age = pd.pivot_table(population_by_age, index=['state', 'county'], columns='agegrp')\n",
    "population_by_age.columns = ['{}_{}'.format(t, v) for v,t in population_by_age.columns]\n",
    "population_by_age = population_by_age.reset_index()\n",
    "# keep only total population rows for race columns\n",
    "demo_data = demo_data[demo_data.agegrp=='agegrp_tot'].drop(columns='agegrp')\n",
    "# concatenate with age groups columns\n",
    "demo_data = demo_data.merge(population_by_age, how='inner', on=['state', 'county'])\n",
    "# make fips codes standard\n",
    "demo_data.county = demo_data.county.astype(str).apply(lambda x: '00'+ x if len(x)==1 else '0'+x if len(x)==2 else x)\n",
    "demo_data['countyfips'] = demo_data[['state', 'county']].apply(lambda row: str(row.state)+row.county, axis=1).astype('int64')\n",
    "demo_data.insert(3, 'countyfips', demo_data.pop('countyfips'))\n",
    "# calculate percent of population of a particular race as  % of  total population in a county\n",
    "race_percent_dict = {}\n",
    "for r in ['race_ba',\t'race_ia',\t'race_aa',\t'race_na',\t'race_tom', 'race_wa']:\n",
    "  name = r + '_%'\n",
    "  race_percent_dict[name] = demo_data.apply(lambda row: np.round(row[r]/row['population'], 2)*100, axis=1).to_list()\n",
    "race_data_percent_df = pd.DataFrame(race_percent_dict)\n",
    "# calculate percent of population of a particular race as  % of  total population of this race in a county (to see the life length of representatives of each race)\n",
    "race_by_age_percent_dict = {}\n",
    "for r in ['aa', 'ba', 'ia', 'na', 'wa', 'tom']:\n",
    "  for a in ['1', '2', '3', '4']:\n",
    "    name = 'race_' + r + '_agegrp_' + a + '%'\n",
    "    race_by_age_percent_dict[name] = population_by_race_gender_agegroup.apply(lambda row: np.round(row['agegrp_'+a+'_race_'+r]/(row['agegrp_tot_race_'+r]+0.00001), 2)*100, axis=1).to_list()\n",
    "race_by_age_percent_df = pd.DataFrame(race_by_age_percent_dict)\n",
    "# combine with demographics dataframe\n",
    "demo_data = pd.concat([demo_data, race_data_percent_df, race_by_age_percent_df], axis=1)\n",
    "\n",
    "# Unemploymnet data\n",
    "unemp_columns = ['fips_code', 'unemployment_rate_2020', 'median_household_income_2020']\n",
    "unemp_data = unemployment_data[unemp_columns].rename(columns={'fips_code':'countyfips'})\n",
    "\n",
    "# mortality data\n",
    "mrt_data = mort_data.rename(columns={'county code':'countyfips', 'crude rate':'mort_cruderate'})\n",
    "mrt_data.countyfips = mrt_data.countyfips.apply(lambda x: x.replace('\"', '')).astype('int64')\n",
    "# mrt_data = mrt_data[['countyfips', 'deaths', 'mort_cruderate']]\n",
    "mrt_data.deaths = mrt_data.deaths.astype('int64')\n",
    "mort_data.state = mort_data.state.fillna('').apply(lambda x: x.replace('\"', ''))\n",
    "# convert deaths to crude rates per 1000 \n",
    "mrt_data = mort_data.rename(columns={'county code':'countyfips', 'crude rate':'mort_cruderate'})\n",
    "mrt_data.countyfips = mrt_data.countyfips.apply(lambda x: x.replace('\"', '')).astype('int64')\n",
    "mrt_data['mort_cruderate'] = mrt_data.apply(lambda row: (int(row['deaths'])/int(row['population']))*1000, axis=1)\n",
    "\n",
    "# poverty data\n",
    "pov_data = poverty_data.rename(columns={'fips_code':'countyfips'})[['stabr', 'countyfips','area_name', 'povall_2020', 'pctpovall_2020']]\n",
    "pov_data = pov_data[pov_data.countyfips.isin(data_pl.countyfips.values)]\n",
    "\n",
    "# education data\n",
    "# Federal Information Processing Standard (FIPS) Code, 2013 Rural-urban Continuum Code, 2013 Urban Influence Code, Percent of adults with less than a high school diploma, 2017-21, Percent of adults with a high school diploma only, 2017-21, Percent of adults completing some college or associate's degree, 2017-21\n",
    "edu_data = education_data.rename(columns={'Federal Information Processing Standard (FIPS) Code'.lower():'countyfips', \\\n",
    "                                          '2013 Rural-urban Continuum Code'.lower():'rural_urban_cont_code',\\\n",
    "                                           '2013 Urban Influence Code'.lower():'urban_inf_code',   \\\n",
    "                                            'Percent of adults with less than a high school diploma, 2017-21'.lower():'adults_no_hs_diploma_percent',\\\n",
    "                                            'Percent of adults with a high school diploma only, 2017-21'.lower():'adults_hs_diploma_only_percent',\\\n",
    "                                              \"Percent of adults completing some college or associate's degree, 2017-21\".lower():'adults_college_diploma_percent',\\\n",
    "                                                \"Percent of adults with a bachelor's degree or higher, 2017-21\".lower():'adults_bachelors_or_higher_percent'})\n",
    "edu_data = edu_data[['countyfips', 'rural_urban_cont_code', 'urban_inf_code', \\\n",
    "                     'adults_no_hs_diploma_percent', 'adults_hs_diploma_only_percent', \\\n",
    "                        'adults_college_diploma_percent', 'adults_bachelors_or_higher_percent' ]] \n",
    "\n",
    "# SVI data\n",
    "# FIPS,EP_DISABL,EP_SNGPNT,EP_MINRTY,EP_LIMENG,EP_NOVEH,EP_POV,F_DISABL,F_SNGPNT,F_MINRTY,F_LIMENG,F_NOVEH,F_POV,\n",
    "svi_columns = \"FIPS,EP_DISABL,EP_SNGPNT,EP_MINRTY,EP_LIMENG,EP_NOVEH,EP_POV,F_DISABL,F_SNGPNT,F_MINRTY,F_LIMENG,F_NOVEH,F_POV\".lower().split(',')\n",
    "sv_data = svi_data[svi_columns].rename(columns={'fips':'countyfips'})\n",
    "sv_data.loc[:, sv_data.columns.str.contains('^f', regex=True)].clip(0,1, inplace=True)\n",
    "sv_data.clip(0, inplace=True)\n",
    "\n",
    "# sunshine data\n",
    "sunshine_data['% sun'] = sunshine_data['% sun'].apply(lambda x: x.replace('â€“', '-1')).astype(int)\n",
    "sunshine_data['total hours'] = sunshine_data['total hours'].apply(lambda x: x.replace('â€“', '-1')).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "L2alzITq3xzF",
   "metadata": {
    "id": "L2alzITq3xzF"
   },
   "source": [
    "### Merge datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FakBKay5Pn2V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FakBKay5Pn2V",
    "outputId": "cf380b5d-8e36-4f9a-d4b7-e0f16eff1f64"
   },
   "outputs": [],
   "source": [
    "# merge places with demographics dataset\n",
    "data = pd.merge(data_pl, demo_data.drop(columns=['state', 'county', 'stname', 'ctyname']), how='left', on='countyfips')\n",
    "# merge unemployment with places data\n",
    "data = pd.merge(data, unemp_data, how='left', on='countyfips')\n",
    "# merge mortality with places data\n",
    "data = pd.merge(data, mrt_data, how='left', on='countyfips')\n",
    "# merge poverty with places data\n",
    "data = pd.merge(data, pov_data, how='left', on='countyfips')\n",
    "# merge education data with places data\n",
    "data = pd.merge(data, edu_data, how='left', on='countyfips')\n",
    "# merge SVI data  with places data\n",
    "data = pd.merge(data, sv_data, how='left', on='countyfips')\n",
    "# merge with sunshine data\n",
    "data = data.merge(sunshine_data.rename(columns={'state':'statedesc'}), how='left', on='statedesc')\n",
    "\n",
    "data['countyfips'] = data['countyfips'].apply(lambda x: '0'+str(x) if len(str(x))<5 else x)\n",
    "\n",
    "print('The shape of the resulting dataframe is: ', data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f531f84-3902-4a74-8911-a6f2dfa6673b",
   "metadata": {
    "id": "4f531f84-3902-4a74-8911-a6f2dfa6673b"
   },
   "source": [
    "## 2. Visualization Task\n",
    "Using the data you created in Section `1.0`, perform an Exploratory Data Analysis (EDA). EDA consists of generating several cross tabulations, summary statistics and graphical representations of the data that help:\n",
    "\n",
    "1. Identify patterns in county characteristics that are associated with the prevalence of health conditions.\n",
    "2. Detect oddities/errors in the data (if any) that may confound the results of a model trained to predict health conditions (if not accounted for)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lxNRdcrD3jeh",
   "metadata": {
    "id": "lxNRdcrD3jeh"
   },
   "source": [
    "### Health conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B2_-9jCRtOvw",
   "metadata": {
    "id": "B2_-9jCRtOvw"
   },
   "outputs": [],
   "source": [
    "# group columns by their meanings\n",
    "risk_behaviors = ['binge_crudeprev', 'csmoking_crudeprev', 'sleep_crudeprev', 'lpa_crudeprev']\n",
    "prevention = ['access2_crudeprev', 'checkup_crudeprev', 'dental_crudeprev', 'bpmed_crudeprev', 'cholscreen_crudeprev', 'mammouse_crudeprev', 'cervical_crudeprev',\\\n",
    "              'corem_crudeprev', 'corew_crudeprev', 'colon_screen_crudeprev']\n",
    "outcomes = ['arthritis_crudeprev', 'casthma_crudeprev', 'bphigh_crudeprev', 'cancer_crudeprev', 'highchol_crudeprev', 'kidney_crudeprev', 'copd_crudeprev',\\\n",
    "            'chd_crudeprev', 'diabetes_crudeprev', 'depression_crudeprev', 'obesity_crudeprev', 'stroke_crudeprev', 'teethlost_crudeprev']\n",
    "health_status = ['ghlth_crudeprev', 'phlth_crudeprev', 'mhlth_crudeprev']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9M88bH-J7m-S",
   "metadata": {
    "id": "9M88bH-J7m-S"
   },
   "source": [
    "Leading health risk behaviors among USA counties are **sleeping less than 7 hours and lack of physical activity**. The prevalent health outcomes are **high blood pressure and cholesterol, obesity**, where obesity have the highest maximum crude rate value of around 52 â¬‡ï¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324309a5-e014-4be6-8f4d-b0180bc32f7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "324309a5-e014-4be6-8f4d-b0180bc32f7e",
    "outputId": "34ab7df7-85db-4028-e2f6-ee19a3eb048c"
   },
   "outputs": [],
   "source": [
    "print('Shape of places dataset is: ', data_pl.shape)\n",
    "data_pl[risk_behaviors].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09HlA0q3yV9H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "09HlA0q3yV9H",
    "outputId": "bbfa22e3-645b-422b-c582-29553cc7d0d9"
   },
   "outputs": [],
   "source": [
    "data_pl[health_status].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-yrW8K3Uyhw9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "-yrW8K3Uyhw9",
    "outputId": "2a7fd5da-f728-4d0a-855a-066d497e8358"
   },
   "outputs": [],
   "source": [
    "data_pl[outcomes].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wqa2oULuJrN2",
   "metadata": {
    "id": "wqa2oULuJrN2"
   },
   "source": [
    "#### Obesity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "I3KMPap5BfH8",
   "metadata": {
    "id": "I3KMPap5BfH8"
   },
   "source": [
    "Obesity is one of the most prevalent health outcomes across US counties. This ailment is more common in the south-eastern states of US and Alaska â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v4doloko8sCX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v4doloko8sCX",
    "outputId": "739b3edf-69cd-4e90-84b2-29adfea11aed"
   },
   "outputs": [],
   "source": [
    "data_pl.nlargest(5, 'obesity_crudeprev')[['statedesc', 'countyname', 'obesity_crudeprev']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cIM5Rz8DUf9u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "cIM5Rz8DUf9u",
    "outputId": "4fc432fa-6a6d-459e-a2e3-785936230c15"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data, geojson=counties, locations='countyfips', color='obesity_crudeprev',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(17, 40),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'obesity_crudeprev':'obesity rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dqoijeDQVYsF",
   "metadata": {
    "id": "dqoijeDQVYsF"
   },
   "source": [
    "â¬†ï¸ Obesity crude prevalence rates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9yhiM7IhJx9R",
   "metadata": {
    "id": "9yhiM7IhJx9R"
   },
   "source": [
    "#### Health insurance access"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44yryfLgJn4b",
   "metadata": {
    "id": "44yryfLgJn4b"
   },
   "source": [
    "Rates of people **lacking health insurance** are higher in **southern parts of the country** and in some areas in **Alaska**. There are high rates for **cholesterol screening** and **taking blood pressure medications**, which is consistent with the health outcomes data. In addition, we can see high rates for **cervical cancer screening** and **mammography use** among **women**. However, the rates for adult men and women who are up to date on **core set of clinical preventive services** are quite low, comparing with other preventive measures ratesâ¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_Zu4Mx3_ylJg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "_Zu4Mx3_ylJg",
    "outputId": "a04f213d-bdd0-471f-9db8-f3914d74fcd4"
   },
   "outputs": [],
   "source": [
    "data_pl[prevention].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UJP9phrdVe9v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "UJP9phrdVe9v",
    "outputId": "43e95de3-4b17-4334-eb6e-bd1e9d98dfe5"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data, geojson=counties, locations='countyfips', color='access2_crudeprev',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(5, 25),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'access2_crudeprev':'current lack of health insurance'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "XOLClciTWU6s",
   "metadata": {
    "id": "XOLClciTWU6s"
   },
   "source": [
    "â¬†ï¸ Lack of health insurance crude prevalence rates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "tRxrFin7J8zx",
   "metadata": {
    "id": "tRxrFin7J8zx"
   },
   "source": [
    "#### Health and health risk behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AOO5CHp5v3JT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "AOO5CHp5v3JT",
    "outputId": "79211f8f-0b77-444b-e9cc-d16f77e1d894"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# convert values of health risk behaviors rates to categorical variables, \n",
    "# where 'low' category corresponds to values below 1st quartile, moderate between 1st and 3rd, and high - above 3rd quartile\n",
    "# data_pl[['lpa_crudeprev', 'sleep_crudeprev']].describe()\n",
    "lpa_cat = data_pl['lpa_crudeprev'].apply(lambda x: 'high' if x<24 else 'moderate' if x<=30 else 'low')\n",
    "sleep_cat = data_pl['sleep_crudeprev'].apply(lambda x: 'high' if x<30 else 'moderate' if x<=36 else 'low')\n",
    "# data_pl[['binge_crudeprev', 'csmoking_crudeprev']].describe()\n",
    "binge_cat = data_pl['binge_crudeprev'].apply(lambda x: 'low' if x<10 else 'moderate' if x<=18 else 'high')\n",
    "smoking_cat = data_pl['csmoking_crudeprev'].apply(lambda x: 'low' if x<10 else 'moderate' if x<=18 else 'high')\n",
    "\n",
    "# plot cross tabulations as heatmaps\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\n",
    "title = fig.suptitle('Ð•he effect of health risk behaviors on health rates\\n', fontsize=16)\n",
    "\n",
    "cross_tab_sleep_lpa_phlth = sns.heatmap(pd.crosstab(lpa_cat, sleep_cat, data_pl['phlth_crudeprev'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"Blues\", ax=ax1)\n",
    "_ = cross_tab_sleep_lpa_phlth.set_xlabel(\"physical activity\",fontsize=12)\n",
    "_ = cross_tab_sleep_lpa_phlth.set_ylabel(\"sleep quality\", fontsize=12)\n",
    "_ = cross_tab_sleep_lpa_phlth.set_title(\"Poor physical health rate\", fontsize=15)\n",
    "\n",
    "cross_tab_sleep_lpa_mhlth = sns.heatmap(pd.crosstab(lpa_cat, sleep_cat, data_pl['mhlth_crudeprev'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"Blues\", ax=ax2)\n",
    "_ = cross_tab_sleep_lpa_mhlth.set_xlabel(\"physical activity\",fontsize=12)\n",
    "_ = cross_tab_sleep_lpa_mhlth.set_ylabel(\"sleep quality\", fontsize=12)\n",
    "_ = cross_tab_sleep_lpa_mhlth.set_title(\"Poor mental health rate\", fontsize=15)\n",
    "\n",
    "cross_tab_binge_smoking_phlth = sns.heatmap(pd.crosstab(binge_cat, smoking_cat, data_pl['phlth_crudeprev'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"Blues\", ax=ax3)\n",
    "_ = cross_tab_binge_smoking_phlth.set_xlabel(\"binge drinking rate\",fontsize=12)\n",
    "_ = cross_tab_binge_smoking_phlth.set_ylabel(\"currently smoking rate\", fontsize=12)\n",
    "_ = cross_tab_binge_smoking_phlth.set_title(\"Poor physical health rate\", fontsize=15)\n",
    "\n",
    "cross_tab_binge_smoking_mhlth = sns.heatmap(pd.crosstab(binge_cat, smoking_cat, data_pl['mhlth_crudeprev'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"Blues\", ax=ax4)\n",
    "_ = cross_tab_binge_smoking_mhlth.set_xlabel(\"binge drinking rate\",fontsize=12)\n",
    "_ = cross_tab_binge_smoking_mhlth.set_ylabel(\"currently smoking rate\", fontsize=12)\n",
    "_ = cross_tab_binge_smoking_mhlth.set_title(\"Poor mental health rate\", fontsize=15)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sjsrJ6QYJW0G",
   "metadata": {
    "id": "sjsrJ6QYJW0G"
   },
   "source": [
    "â¬†ï¸ The heatmaps above shows the mean rates of self-reported physical and mental health, depending on the health risk behaviors rates.\n",
    "\n",
    "\n",
    "We can see that lack of sleep and physical activity do affect all types of people's health. However, low and moderate **sleep quality** correlates with **physical health** the most, whereas **physical inactivity** has strong association with **mental health**.\n",
    "\n",
    "\n",
    "High **binge drinking** rates correlates with all types of health, especially with **mental health** of the population.\n",
    "\n",
    "\n",
    "ðŸ’¡ We also see that **smoking** rates **positively correlate with health rates**, which is not obvious. The reason might be behind the survey question itself. The description of the given rate is formulated as follows:  \"*Respondents aged â‰¥18 years who report having smoked â‰¥100 cigarettes in their lifetime and currently smoke every day or some days.*\"\n",
    "Therefore, people who had been smoking for a long time but currently do not smoke (probably because of medical reasons) - also considered as not smoking in this survey, which can inject some **noise** in the population smoking rates."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "SI2_TqwEaAIA",
   "metadata": {
    "id": "SI2_TqwEaAIA"
   },
   "source": [
    "### Mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bspcB70xaFlC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "bspcB70xaFlC",
    "outputId": "fc35ffd6-60fb-4624-da88-a62c2e5e1463"
   },
   "outputs": [],
   "source": [
    "print('Shape of mortality dataset is: ', mort_data.shape)\n",
    "mrt_data[mrt_data['mort_cruderate'] != -1].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wDrODPZCKC7K",
   "metadata": {
    "id": "wDrODPZCKC7K"
   },
   "source": [
    "#### States with highest mortality rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CjeB_ZTDquO7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "CjeB_ZTDquO7",
    "outputId": "4ba00281-15cd-4b6b-c240-7ff2ebe4bcdc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ioff()\n",
    "sns.set(context=\"paper\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,6), sharey=True)\n",
    "\n",
    "mort_barplot = sns.barplot(data=data[data['mort_cruderate'] != -1][['statedesc', 'mort_cruderate']].groupby('statedesc')\\\n",
    "                           .mean().reset_index().sort_values('mort_cruderate', ascending=False).head(15), \\\n",
    "                           x='statedesc', y='mort_cruderate', palette='muted', ax=ax1)\n",
    "ticks = plt.setp(mort_barplot.get_xticklabels(), rotation=90, size=12)\n",
    "mort_barplot.set_ylabel('Mortality rates by state', fontsize=12)\n",
    "mort_barplot.set_xlabel('', fontsize=12)\n",
    "title = mort_barplot.set_title('States with the highest mortality rates\\n', fontsize=20)\n",
    "\n",
    "mort_barplot2 = sns.barplot(data=data[data['mort_cruderate'] != -1][['statedesc', 'mort_cruderate']].groupby('statedesc')\\\n",
    "                           .mean().reset_index().sort_values('mort_cruderate', ascending=True).head(15), \\\n",
    "                           x='statedesc', y='mort_cruderate', palette='muted', ax=ax2)\n",
    "ticks = plt.setp(mort_barplot2.get_xticklabels(), rotation=90, size=12)\n",
    "mort_barplot2.set_ylabel('Mortality rates by state', fontsize=12)\n",
    "mort_barplot2.set_xlabel('', fontsize=12)\n",
    "title = mort_barplot2.set_title('States with the lowest mortality rates\\n', fontsize=20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Qi71soUGw9bs",
   "metadata": {
    "id": "Qi71soUGw9bs"
   },
   "source": [
    "Majority of countries have mortality rates between 11 and 15 per 1000. *Mississippi, Arkansas, Alabama, West Virginia, Tennessee* - are states with the **highest mortality** rates in counties. On the other hand, *Alaska, Utah, Hawaii, District of Columbia, California, Washington* - have the **lowest mortality** rates in their counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KTK8t4Q7lQzg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "KTK8t4Q7lQzg",
    "outputId": "0e735e0a-9b29-4c6f-d153-00da1915ea82"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data[data['mort_cruderate']!=-1], geojson=counties, locations='countyfips', color='mort_cruderate',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(1, 20),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'mort_cruderate':'mortality rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lz2K4yUTmBX_",
   "metadata": {
    "id": "lz2K4yUTmBX_"
   },
   "source": [
    "â¬†ï¸ Mortality rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "vyasUO2CKMxy",
   "metadata": {
    "id": "vyasUO2CKMxy"
   },
   "source": [
    "#### Mortality and Social Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ntzRlmPb6uXu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ntzRlmPb6uXu",
    "outputId": "78fd034d-b461-470e-a939-41b4c9fe1b30"
   },
   "outputs": [],
   "source": [
    "data[['ep_minrty', 'ep_disabl', 'ep_sngpnt', 'ep_limeng', 'ep_noveh', 'ep_pov', 'mort_cruderate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vl0qsqmJ6Wri",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "vl0qsqmJ6Wri",
    "outputId": "55e10c67-f4cc-4c12-b717-9a2e25a4443f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# convert values of health risk behaviors rates to categorical variables, \n",
    "minority_cat = data['ep_minrty'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "disabl_cat = data['ep_disabl'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "sngpnt_cat = data['ep_sngpnt'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "limeng_cat = data['ep_limeng'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "noveh_cat = data['ep_noveh'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "pov_cat = data['ep_pov'].apply(lambda x: 'low' if x<5 else 'moderate' if x<=15 else 'high')\n",
    "\n",
    "# plot cross tabulations as heatmaps\n",
    "fig, ((ax1, ax2, ax3)) = plt.subplots(nrows=1, ncols=3, figsize=(13,4))\n",
    "title = fig.suptitle('Social vulnerability and mortality rates\\n', fontsize=16)\n",
    "\n",
    "cross_tab_mort_mnrt_pov = sns.heatmap(pd.crosstab(minority_cat, pov_cat, data['mort_cruderate'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"BuPu\", ax=ax1)\n",
    "_ = cross_tab_mort_mnrt_pov.set_xlabel(\"poverty level\",fontsize=12)\n",
    "_ = cross_tab_mort_mnrt_pov.set_ylabel(\"minority representatives rate\", fontsize=12)\n",
    "\n",
    "\n",
    "cross_tab_mort_disabl_noveh = sns.heatmap(pd.crosstab(disabl_cat, noveh_cat, data['mort_cruderate'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"BuPu\", ax=ax2)\n",
    "_ = cross_tab_mort_disabl_noveh.set_xlabel(\"households with no vehicle rate\",fontsize=12)\n",
    "_ = cross_tab_mort_disabl_noveh.set_ylabel(\"population with disabilities rate\", fontsize=12)\n",
    "\n",
    "cross_tab_mort_snglpnt_limeng = sns.heatmap(pd.crosstab(sngpnt_cat, limeng_cat, data['mort_cruderate'], \\\n",
    "                                                    aggfunc='mean'), annot=True, cmap=\"BuPu\", ax=ax3)\n",
    "_ = cross_tab_mort_snglpnt_limeng.set_xlabel(\"'english 'less than well'\",fontsize=12)\n",
    "_ = cross_tab_mort_snglpnt_limeng.set_ylabel(\"single parent households\", fontsize=12)\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3fdbTdSFmgq",
   "metadata": {
    "id": "d3fdbTdSFmgq"
   },
   "source": [
    "Several features addressing social vulnerability of the population are linked to mortality rates. For example, high **poverty** levels and high population with **disabilities** rates are associated with **higher mortality**.\n",
    "\n",
    "\n",
    "ðŸ’¡*We also can notice that counties with a low rate of people who speak English 'less than well' have higher mortality, and counties with more people speaking English well have higher mortality. This phenomenon can be related to the fact that people starting from 5 years old were counted in for this rate estimation. Children born in non-English speaking families most probably learn English much later in life. Therefore, a community with a higher number of such children has a higher 'English less than well' rate. However, the mean age is lower in that community, which may result in the lower mortality rate (since people pass away in older age normally).*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "s3coCosCq7zD",
   "metadata": {
    "id": "s3coCosCq7zD"
   },
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sOmhlHKqPKAR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "sOmhlHKqPKAR",
    "outputId": "3bd5d5fd-e636-47b3-da9c-c0a0a4ed0344"
   },
   "outputs": [],
   "source": [
    "print('Shape of demographics dataset is: ', demo_data.shape)\n",
    "demo_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "UThugnuAKY5j",
   "metadata": {
    "id": "UThugnuAKY5j"
   },
   "source": [
    "#### Population by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PQu7bLNmsuik",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "PQu7bLNmsuik",
    "outputId": "b8f7bb62-b9fa-40a2-af18-550d0f396648"
   },
   "outputs": [],
   "source": [
    "demo_data.nlargest(3, 'population')[['ctyname', 'population']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Y4yFKw71xwre",
   "metadata": {
    "id": "Y4yFKw71xwre"
   },
   "source": [
    "Median population of male and female is around 13.000, with **male** median population is slightly **higher** across counties. Majority of counties have population between **11.000** and **70.000**. However, there are some outliers in terms of population sizes, such as large counties inside big cities such *Los Angeles County*, *Cook County*, *Harris County*, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oMBt03ZBq62w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "oMBt03ZBq62w",
    "outputId": "2d27fbe9-1e62-410e-8e61-bb8de63992b0"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(20.,5.)})\n",
    "population_boxplot =  sns.boxplot(data=demo_data[['population', 'male', 'female']].clip(0, demo_data.population.describe()['75%']), orient=\"h\")\n",
    "xticks = population_boxplot.set_xticks(range(0, int(demo_data.population.describe()['75%']), 5000))\n",
    "title = population_boxplot.set_title('Population distribution by gender across USA counties\\n', fontsize=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nHjibjHQKfjH",
   "metadata": {
    "id": "nHjibjHQKfjH"
   },
   "source": [
    "#### Population by race"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ZMN0DL_E8QfU",
   "metadata": {
    "id": "ZMN0DL_E8QfU"
   },
   "source": [
    "The people of white race make up between 78% and 95% of the population in the majority of counties. However, we see that in some counties the majority belong to other races (outlier dots on the boxplot), such as black or american indian and alaska native. Small part (<10%) of the population consists of people of two and more races.\n",
    "\n",
    "\n",
    "Key to race coding map:\n",
    "- ba - black of african alone\n",
    "- ia - american indian and alaska native alone\n",
    "- aa - asian alone\n",
    "- na - native hawaiian and other pacific islander alone\n",
    "- wa - white alone\n",
    "- tom - two or more races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZvkIdWxdAvGt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "ZvkIdWxdAvGt",
    "outputId": "b466b528-55a0-4a29-c42c-fb51169f286a"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(20.,5.)})\n",
    "population_boxplot =  sns.boxplot(data=race_data_percent_df, orient=\"h\")\n",
    "xticks = population_boxplot.set_xticks(range(0, 110, 10))\n",
    "title = population_boxplot.set_title('Population distribution by race across USA counties, % of total county population\\n', fontsize=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "tJBEUh0DKnNt",
   "metadata": {
    "id": "tJBEUh0DKnNt"
   },
   "source": [
    "#### Race and length of life "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rGTsMzAL2RYC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "rGTsMzAL2RYC",
    "outputId": "bec72cfc-d263-4ad9-d682-049234973aaa"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "race_by_age_group_visual = demo_data.loc[:, demo_data.columns.str.contains(r'(^race.*\\d%$)|(state)|(county)', regex=True)]\n",
    "\n",
    "labels = ['0-19 years', '20-39 years', '40-64 years', '65+ years']\n",
    "colors = ['#88d8b0', '#ffcc5c', '#ff6f69', '#4279a3']\n",
    "\n",
    "fig, ((ax0, ax1, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3, figsize=(18, 8))\n",
    "\n",
    "ax0.hist(race_by_age_group_visual[['race_aa_agegrp_1%', 'race_aa_agegrp_2%', 'race_aa_agegrp_3%', 'race_aa_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax0.legend(title='Asian', loc='upper right')\n",
    "\n",
    "ax1.hist(race_by_age_group_visual[['race_ba_agegrp_1%', 'race_ba_agegrp_2%', 'race_ba_agegrp_3%', 'race_ba_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax1.legend(title='Black or African American', loc='upper right')\n",
    "\n",
    "ax3.hist(race_by_age_group_visual[['race_wa_agegrp_1%', 'race_wa_agegrp_2%', 'race_wa_agegrp_3%', 'race_wa_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax3.legend(title='White', loc='upper right')\n",
    "\n",
    "ax4.hist(race_by_age_group_visual[['race_ia_agegrp_1%', 'race_ia_agegrp_2%', 'race_ia_agegrp_3%', 'race_ia_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax4.legend(title='American Indian and Alaska Native', loc='upper right')\n",
    "\n",
    "ax5.hist(race_by_age_group_visual[['race_na_agegrp_1%', 'race_na_agegrp_2%', 'race_na_agegrp_3%', 'race_na_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax5.legend(title='Native Hawaiian and Other Pacific Islander', loc='upper right')\n",
    "\n",
    "ax6.hist(race_by_age_group_visual[['race_tom_agegrp_1%', 'race_tom_agegrp_2%', 'race_tom_agegrp_3%', 'race_tom_agegrp_4%']], bins=100, histtype='step', color=colors, label=labels, alpha=0.7)\n",
    "ax6.legend(title='Two or More Races', loc='upper right')\n",
    "\n",
    "fig.text(0.5, 0.04, '% of people of age X from a total population of a race Y', ha='center', va='center', fontsize=16)\n",
    "fig.text(0.06, 0.5, 'n of counties', ha='center', va='center', rotation='vertical', fontsize=16)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "S3WbZ47Keaz_",
   "metadata": {
    "id": "S3WbZ47Keaz_"
   },
   "source": [
    "â¬†ï¸ The following figure shows the percent of people of a given **race** in a given **age group** to the total number of people of that race in a county. For example, similar proportions of people of all age groups, means that this population has a long life length. On the other hand, if the percentage of older people is smaller, that would mean that people's life length is smaller.\n",
    "\n",
    "\n",
    "We can see from the figure above that for representatives of **all races have shorter life length than people of white race**. For white race the percentage of  people above 65 years old is bigger, compared to other races. This might mean that people of other races in the majority of cases have  worse living conditions than people of white race."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dJy3k8yfOLdU",
   "metadata": {
    "id": "dJy3k8yfOLdU"
   },
   "source": [
    "### Poverty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7hU5DK0IUIP7",
   "metadata": {
    "id": "7hU5DK0IUIP7"
   },
   "source": [
    "Median proportion of people in poverty across US counties is around 13%. The maximum poverty proportion reaches a value of almost 44% (of total county population). Majority of US counties have poverty level below 17% â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vhIuA5M4OMdG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "vhIuA5M4OMdG",
    "outputId": "d67695aa-89bb-493f-98a0-c6f2ec1c13fd"
   },
   "outputs": [],
   "source": [
    "print('Shape of poverty dataset is: ', pov_data.shape)\n",
    "pov_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5V86ocCePk8M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "5V86ocCePk8M",
    "outputId": "f2cae70d-03c4-454e-9ee2-1168a6db150b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "sns.set(context=\"paper\")\n",
    "\n",
    "pov_barplot = sns.barplot(data=pov_data.nlargest(100, 'pctpovall_2020'), x='stabr', y='pctpovall_2020', palette='muted')\n",
    "ticks = plt.setp(pov_barplot.get_xticklabels(), rotation=0, size=10)\n",
    "pov_barplot.set_ylabel('people in poverty, \\n% of total county population\\n (average)', fontsize=12)\n",
    "pov_barplot.set_xlabel('', fontsize=12)\n",
    "title = pov_barplot.set_title('Counties with the highest poverty level by state\\n', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a3c7PmUVYND",
   "metadata": {
    "id": "1a3c7PmUVYND"
   },
   "source": [
    "These states include 100 counties with the highest poverty levels, grouped by states. The bar plot shows the average percentage of poverty, and  vertical lines show the 95% CI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Vz52RsTyRSMp",
   "metadata": {
    "id": "Vz52RsTyRSMp"
   },
   "source": [
    "- SD - South Dakota\n",
    "- MS - Mississippi\n",
    "- GA - Georgia\n",
    "- LA - Louisiana\n",
    "- KY - Kentucky\n",
    "- CO - Colorado\n",
    "- AR - Arkansas\n",
    "- TN - Tennessee\n",
    "- MO - Missouri\n",
    "- AZ - Arizona\n",
    "- NM - New Mexico\n",
    "- WV - West Virginia\n",
    "- SC - South Carolina\n",
    "- AL - Alabama\n",
    "- NC - North Carolina\n",
    "- MT - Montana\n",
    "- TX - Texas\n",
    "- ND - North Dakota\n",
    "- AK - Alaska\n",
    "- VA - Virginia\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGLrr20-XPYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "PGLrr20-XPYf",
    "outputId": "531a6170-5847-4c9d-f43a-ebb602e5f919"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data, geojson=counties, locations='countyfips', color='pctpovall_2020',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(3, 20),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'pctpovall_2020':'poverty rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "K8jhhSAmXxYE",
   "metadata": {
    "id": "K8jhhSAmXxYE"
   },
   "source": [
    "â¬†ï¸ The map shows poverty rates across US counties.\n",
    "The patterns of poverty rates and lack of health insurance rates partially coincides. This is corresponds with the intuition behind this phenomenon: **people below poverty level tend not to buy health insurance plans**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "qChF5kI0OTC-",
   "metadata": {
    "id": "qChF5kI0OTC-"
   },
   "source": [
    "### Education and general health"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "K1MDjIfd0_s8",
   "metadata": {
    "id": "K1MDjIfd0_s8"
   },
   "source": [
    "In the majority of US counties around 33% of adults have only a high school diploma, around 31% completed some college or associate's degree, 21% have bachelor's degree or higher, and around 11% of adults do not have a high school diploma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VHN6hROOOSU4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "VHN6hROOOSU4",
    "outputId": "2df20e7a-b384-426c-d6e5-d677ceaef082"
   },
   "outputs": [],
   "source": [
    "print('Shape of education dataset is: ', edu_data.shape)\n",
    "edu_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fyW5mYqo6Qu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "4fyW5mYqo6Qu",
    "outputId": "4535e0bb-26b6-48a4-a989-da92dfbb8ecc"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ((ax1,ax2)) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5), sharey=False)\n",
    "fig.suptitle(\"Education and 'poor general health' rates\", fontsize=15)\n",
    "\n",
    "edu_scatter1 = ax1.scatter(x=data['adults_no_hs_diploma_percent'], y=data['adults_hs_diploma_only_percent'], \\\n",
    "                           c=data['ghlth_crudeprev'], s=7, vmin=5, vmax=30, alpha=0.6, cmap='viridis')\n",
    "ax1.set_xlabel('adults with no high school diploma, %', fontsize=12)\n",
    "ax1.set_ylabel('adults with high school diploma only, %', fontsize=10)\n",
    "ax1.set_facecolor('#f7f7f7')\n",
    "ax1.set_title('Figure 1')\n",
    "plt.colorbar(edu_scatter1)\n",
    "\n",
    "edu_scatter2 = ax2.scatter(x=data['adults_college_diploma_percent'], y=data['adults_bachelors_or_higher_percent'], \\\n",
    "                           c=data['ghlth_crudeprev'], s=7, vmin=5, vmax=30, alpha=0.6, cmap='viridis')\n",
    "ax2.set_xlabel(\"adults completing some \\n college or associate's degree, %\", fontsize=12)\n",
    "ax2.set_ylabel(\"adults with \\na bachelor's degree or higher, %\", fontsize=10)\n",
    "ax2.set_facecolor('#f7f7f7')\n",
    "ax2.set_title('Figure 2')\n",
    "plt.colorbar(edu_scatter2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "GwKJhGhY0tWU",
   "metadata": {
    "id": "GwKJhGhY0tWU"
   },
   "source": [
    "â¬†ï¸ Level of education and general health.\n",
    "\n",
    "\n",
    "*Note, that*\n",
    "- ðŸŸ¡ yellow color denotes high rates of people with poor self-reported general health (or not good general health in a county population)\n",
    "- ðŸŸ£ purple color denotes low rates of poor self-reported general health (or good general health in a county population).\n",
    "\n",
    "\n",
    "From Figure 1, we see that counties with high percent of people **not having high school diploma** characterized by high rates of **'poor general health'**. If a big part of the population in a county has only a high school diploma, it does not affect health rates much. However, if there are big percent of people without high school diplomas AND with only high school diplomas - it negatively affects health rates, in other words, yields high 'poor general health' rates.\n",
    "\n",
    "\n",
    "From this we can infer, that **level of education** is **positively associated with health rates**. \n",
    "\n",
    "From Figure 2 we can see that indeed, the more people in a county have completed some college and have received at least bachelor's degree, the better health rates (purple color means low \"poor general health\" rates).\n",
    "\n",
    "*Note*, that it does NOT mean that low levels of education cause poor general health. The poverty can be causing both: low level of education and poor health*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pLV4lKH5PRqn",
   "metadata": {
    "id": "pLV4lKH5PRqn"
   },
   "source": [
    "### Mental health and median household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gLViczB1POfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "gLViczB1POfe",
    "outputId": "7f07f494-827c-4d51-a52b-c4ec8a6772fb"
   },
   "outputs": [],
   "source": [
    "print('Shape of unemployment dataset is: ', data.shape)\n",
    "data[['countyfips',\t'unemployment_rate_2020',\t'median_household_income_2020']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qFywnDA5e1mz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "qFywnDA5e1mz",
    "outputId": "edbd1365-7e1c-41dd-d5d1-ba8b4cc4ca75"
   },
   "outputs": [],
   "source": [
    "data[['depression_crudeprev', 'mhlth_crudeprev']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C3E7YdJMQAdG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "C3E7YdJMQAdG",
    "outputId": "ce31841c-5aa1-4cc3-9d3b-41bc3b3cada5"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data, geojson=counties, locations='countyfips', color='mhlth_crudeprev',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(8, 19),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'mhlth_crudeprev':'mental health \\nnot good rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AwtX7F7p8k9B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "AwtX7F7p8k9B",
    "outputId": "c2b747ec-a5de-4f53-8eba-8c5cb189a0f9"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth_mapbox(data, geojson=counties, locations='countyfips', color='median_household_income_2020',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(25000, 100000),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'mhlth_crudeprev':'mental health \\nnot good rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "-X8HNprZeWeX",
   "metadata": {
    "id": "-X8HNprZeWeX"
   },
   "source": [
    "The above two maps shows the median **household income** rates and **poor mental health** rates across US counties.\n",
    "\n",
    "\n",
    "According to the maps, there is **no strong linear correlation** between these two factors.\n",
    "\n",
    "\n",
    "However, in some areas with high median household income, such as **District of Columbia, New York,** and **San Francisco**, **mental health** rates are **better**. Similarly, in most of counties located in **Louisiana, Alabama, Georgia, Kentucky** where the median household income is low, **poor mental health** rates are high."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dffe6a69-fdc3-40c2-bd94-67b0ed6ed227",
   "metadata": {
    "id": "dffe6a69-fdc3-40c2-bd94-67b0ed6ed227"
   },
   "source": [
    "## 3. Algorithm Task\n",
    "Using the data you created in `Section 1.0` and based on your insights from `Section 2.0`, train a Machine learning algorithm to predict health issues in the county. More specficially, you will need to \n",
    "\n",
    "1. Create a target variable that measures the prevalence of health issues in US counties.\n",
    "2. Create a feature matrix of factors that you believe will predit the target variable.\n",
    "3. Train a machine learning model to predict the target variable from the feature matrix.\n",
    "3. Choose a metric to assess the performance of the trained machine learning algorithm.\n",
    "4. Rank-order the importance of the selected features.\n",
    "\n",
    "You must be able to justify all your choices. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mWL_HcKeGNJI",
   "metadata": {
    "id": "mWL_HcKeGNJI"
   },
   "source": [
    "### Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5AWjRcAQCg4x",
   "metadata": {
    "id": "5AWjRcAQCg4x"
   },
   "outputs": [],
   "source": [
    "# group PLACES dataset columns by their meanings\n",
    "risk_behaviors = ['binge_crudeprev', 'csmoking_crudeprev', 'sleep_crudeprev', 'lpa_crudeprev']\n",
    "prevention = ['access2_crudeprev', 'checkup_crudeprev', 'dental_crudeprev', 'bpmed_crudeprev', 'cholscreen_crudeprev', 'mammouse_crudeprev', 'cervical_crudeprev',\\\n",
    "              'corem_crudeprev', 'corew_crudeprev', 'colon_screen_crudeprev']\n",
    "outcomes = ['arthritis_crudeprev', 'casthma_crudeprev', 'bphigh_crudeprev', 'cancer_crudeprev', 'highchol_crudeprev', 'kidney_crudeprev', 'copd_crudeprev',\\\n",
    "            'chd_crudeprev', 'diabetes_crudeprev', 'depression_crudeprev', 'obesity_crudeprev', 'stroke_crudeprev', 'teethlost_crudeprev']\n",
    "health_status = ['ghlth_crudeprev', 'phlth_crudeprev', 'mhlth_crudeprev']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "v2WJ0yfB2wPW",
   "metadata": {
    "id": "v2WJ0yfB2wPW"
   },
   "source": [
    "To construct target variables, we use supplementary mortality dataset and health outcomes columns from PLACES.\n",
    "\n",
    "\n",
    "We use mortality rates as a direction to weight particular health issues for a county.\n",
    "\n",
    "\n",
    "The more a health issue (health outcome) rate is correlated with mortality rate - the higher weight we assign to this particular health issue.\n",
    "\n",
    "\n",
    "The target variable is constructed in the following way:\n",
    "\n",
    "\n",
    "1. Each feature column multiplied by the correlation coefficient between this feature and mortality rate.\n",
    "3. All feature columns are summed up, resulting into one new feature column.\n",
    "4. The resulting variables are scaled between 0 and 1 using the min max scaling method.\n",
    "5. Substract the resulting variable from 1 to change the direction from 0 to 1, where 0 corresponds to poor population health and 1 corresponds to good population health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tQUSkHq0GhbN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "tQUSkHq0GhbN",
    "outputId": "1bd2a1e8-d5af-4913-8be8-c3042cd4d8ee"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot feature correlation heatmap\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,12))\n",
    "title = fig.suptitle('Correlation of different health outcomes rates with mortlity rates\\n', fontsize=16)\n",
    "\n",
    "data_mort_outcomes_corr = data[[*outcomes, *['mort_cruderate']]].corr(method='spearman')\n",
    "corr_map = sns.heatmap(data_mort_outcomes_corr, annot=True, cmap=\"BuPu\", ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "YOSMVWJUEJkL",
   "metadata": {
    "id": "YOSMVWJUEJkL"
   },
   "source": [
    "â¬†ï¸ The following heatmap shows correlation between different health issues rates and mortality rates. The most correlated with mortality rates health issues are *coronary heart disease, stroke, kidney disease, high blood pressure, arthritis, high cholesterol, chronic obstructive pulmonary disease, diabetes*.\n",
    "\n",
    "\n",
    "We also see that some of the features are highly correlated with each other, such as stroke and kidney disease, diabetes and kidney disease, coronary heart disease and kidney disease, coronary heart disease and  stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eXHr2li5Z8AY",
   "metadata": {
    "id": "eXHr2li5Z8AY"
   },
   "outputs": [],
   "source": [
    "# build a dictionary with correlation coeficients for mortality and each health issue\n",
    "outcomes_mort_coef_map = dict(data_mort_outcomes_corr.loc[:, 'mort_cruderate'][:-1].items())\n",
    "# multiply each column by the coefficient and sum up \n",
    "res = data[outcomes].mul(outcomes_mort_coef_map, axis=1).sum(axis=1).round(decimals=2)\n",
    "# create a dataframe with target variable and mortality rates (for visualizing)\n",
    "target_data = pd.DataFrame()\n",
    "target_data['target_var'] = res.values\n",
    "target_data['mort_cruderate'] = data['mort_cruderate']\n",
    "target_data['countyfips'] = data['countyfips']\n",
    "# scale the resulting variable between 0 and 1\n",
    "min_, max_ = min(res), max(res)\n",
    "target_data['target_var'] = target_data.target_var.apply(lambda x: 1 - (x-min_)/(max_ - min_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AJBaOyw1u0lB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "AJBaOyw1u0lB",
    "outputId": "53700668-6827-4755-e3b8-db2b74684bed"
   },
   "outputs": [],
   "source": [
    "# visualizing the relatipnships between two variables\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "plt1 = sns.scatterplot(target_data, x='target_var',y='mort_cruderate', ax=ax1)\n",
    "_ = plt1.set_xlabel('target variable', fontsize=14)\n",
    "_ = plt1.set_ylabel('mortality rates', fontsize=14)\n",
    "_ = fig.suptitle('Relationships between target variable and mortality rates', fontsize=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "p_9A7dFvESo3",
   "metadata": {
    "id": "p_9A7dFvESo3"
   },
   "source": [
    "From the figure above we can notice that the relationships between target variable and mortality rate are close to **linear**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "vB0nbYXvHZuW",
   "metadata": {
    "id": "vB0nbYXvHZuW"
   },
   "source": [
    "### Feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapwamiKuAE",
   "metadata": {
    "id": "wrapwamiKuAE"
   },
   "outputs": [],
   "source": [
    "# these columns do not yield unique valuable information\n",
    "## data.select_dtypes(include=['object'])\n",
    "cols_to_drop = [ 'stateabbr','statedesc','countyname','geolocation','population_x','notes',\n",
    " 'state code',\n",
    " 'state',\n",
    " 'county',\n",
    " 'year',\n",
    " 'year code',\n",
    " 'deaths',\n",
    " 'population_y',\n",
    " 'crude rate lower 95% confidence interval',\n",
    " 'crude rate upper 95% confidence interval',\n",
    " 'stabr',\n",
    " 'area_name','place',\n",
    "  ]\n",
    "\n",
    "# remove this columns only for visualization purposes\n",
    "flags = ['f_disabl', 'f_sngpnt', 'f_minrty', 'f_limeng', 'f_noveh', 'f_pov']\n",
    "\n",
    "age_groups_123 = ['race_aa_agegrp_1%', 'race_aa_agegrp_2%', 'race_aa_agegrp_3%','race_ba_agegrp_1%', 'race_ba_agegrp_2%', 'race_ba_agegrp_3%',\\\n",
    "                  'race_ia_agegrp_1%', 'race_ia_agegrp_2%', 'race_ia_agegrp_3%','race_na_agegrp_1%', 'race_na_agegrp_2%', 'race_na_agegrp_3%',\\\n",
    "                  'race_wa_agegrp_1%', 'race_wa_agegrp_2%', 'race_wa_agegrp_3%','race_tom_agegrp_1%', 'race_tom_agegrp_2%', 'race_tom_agegrp_3%']\n",
    "\n",
    "race_cols = ['race_wa', 'race_ba', 'race_ia', 'race_aa', 'race_na', 'race_tom']\n",
    "\n",
    "# remove some coulms which are highly correlated with another columns\n",
    "columns_high_corr = ['totalpopulation', 'povall_2020', 'ep_pov', 'total hours', '% sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kyv57bmSOnQM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kyv57bmSOnQM",
    "outputId": "b735143b-8226-409b-8cb0-d6ce0550f7b1"
   },
   "outputs": [],
   "source": [
    "# remove unnecesary columns and columns related to target variable\n",
    "feature_matrix = data.drop(columns=[*['mort_cruderate'], *outcomes, *health_status, *cols_to_drop])\n",
    "print('We have {} features.'.format(feature_matrix.shape[1]))\n",
    "print(feature_matrix.columns.to_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "GHUIs70AcS4l",
   "metadata": {
    "id": "GHUIs70AcS4l"
   },
   "source": [
    "#### Feature correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "COb_8y3lI35L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "COb_8y3lI35L",
    "outputId": "264c358a-1133-42cb-a592-27c96c0566b7"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot feature correlation heatmap\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,20))\n",
    "title = fig.suptitle('Features correlation\\n', fontsize=16)\n",
    "\n",
    "features_corr = feature_matrix.drop(columns=[*['countyfips'], *flags, *age_groups_123, *race_cols]).corr(method='spearman')\n",
    "corr_map = sns.heatmap(features_corr, annot=False, cmap=\"BuPu\", ax=ax)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X1lQbiVmVTm0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1lQbiVmVTm0",
    "outputId": "ff1bb2b1-a34c-4d53-92fd-6e5a3179bdfa"
   },
   "outputs": [],
   "source": [
    "# check dtypes of data columns\n",
    "feature_matrix.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "oScdVa7EXYzQ",
   "metadata": {
    "id": "oScdVa7EXYzQ"
   },
   "source": [
    "The target variable value ranges between 0.0 and 1.0, where 0.0 is the low risk of bad health outcomes, and 1.0 is a high risk of bad health outcomes in a county.\n",
    "\n",
    "\n",
    "We can divide it into several classes, depending on the task and objectives, for example, values between 0.00-0.29 define \"low risk of high rates of adverse health outcomes in a county\", 0.30-0.59 define \"moderate risk of high rates of adverse health outcomes in a county\", and 0.60-1.00 define \"high risk of high rates of adverse health outcomes in a county\".\n",
    "\n",
    "\n",
    "For now, we will use the direct variable value for model building."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Y6txqISZZzUv",
   "metadata": {
    "id": "Y6txqISZZzUv"
   },
   "source": [
    "### Machine learning model building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "qlIHx3jRsMGv",
   "metadata": {
    "id": "qlIHx3jRsMGv"
   },
   "source": [
    " #### **Problem settings**\n",
    "\n",
    "- Task: Since we choose a continuous target variable, the prediction task is **regression**.\n",
    "\n",
    "\n",
    "- The model used in this study is **XGBoost regressor**, since it is one of the state-of-the-art models for tabular data problems, it is fast to train, and it is well interpretable.\n",
    "\n",
    "- Each sample in the training/testing set is a **county**. \n",
    "\n",
    "- Majority of features are crude prevalence rates on **county level**, however, some features are of **state-level**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bmGhOeY0BMBn",
   "metadata": {
    "id": "bmGhOeY0BMBn"
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "UJfN4RzXPEhy",
   "metadata": {
    "id": "UJfN4RzXPEhy"
   },
   "source": [
    "First, we create some functions to facilitate the model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heHllZ5Q0t3H",
   "metadata": {
    "id": "heHllZ5Q0t3H"
   },
   "outputs": [],
   "source": [
    "# Splitting and preparing the data for being passed to the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(feature_matrix, var_names=None, test_size=0.2, random_seed=42, verbose=True):\n",
    "  # we remove categorical variables for now\n",
    "  categorical = ['rural_urban_cont_code', 'urban_inf_code']\n",
    "  if var_names==None:\n",
    "    # save features' names\n",
    "    var_names = feature_matrix.drop(columns=[*['countyfips'], *categorical]).columns\n",
    "\n",
    "  # data split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(feature_matrix[var_names], target_data[['target_var']], \\\n",
    "                                                      test_size=test_size, random_state=random_seed)\n",
    "\n",
    "  # impute categorical variables with zeros\n",
    "  X_train.loc[:, X_train.columns.str.contains('^f', regex=True)] = X_train.loc[:, X_train.columns.str.contains('^f', regex=True)].fillna(0)\n",
    "  X_test.loc[:, X_test.columns.str.contains('^f', regex=True)] = X_test.loc[:, X_test.columns.str.contains('^f', regex=True)].fillna(0)\n",
    "  # impute continuous variables with median\n",
    "  X_train = X_train.fillna(X_train.median())\n",
    "  X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "  if verbose==True:\n",
    "    print('number of NaNs in X_train: {}, X_test:  {}'.format(X_train.isna().sum().sum(), X_test.isna().sum().sum()))\n",
    "    print('Shapes, X_train: {}, X_test: {}, y_train: {}, y_test {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "\n",
    "  # convert to arrays\n",
    "  X_train, X_test, y_train, y_test = np.asarray(X_train.values), np.asarray(X_test.values), np.asarray(y_train.values).ravel(), np.asarray(y_test.values).ravel()\n",
    "\n",
    "  return (X_train, X_test, y_train, y_test), var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BeSWcwtDinN7",
   "metadata": {
    "id": "BeSWcwtDinN7"
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# this function wraps up the model creating, model fitting, and printing the results\n",
    "def fit_xgb(X_train, X_test, y_train, y_test, params=None, metric='mae', random_seed=42):\n",
    "  if params==None:\n",
    "    params = {\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": 4,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"loss\": \"absolute_error\",\n",
    "        \"random_state\": random_seed\n",
    "    }\n",
    "\n",
    "  xgb =  ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "  xgb.fit(X_train, y_train)\n",
    "\n",
    "  if metric=='mse':\n",
    "    mse = mean_squared_error(y_test.reshape(-1, 1), xgb.predict(X_test))\n",
    "    print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "  if metric=='mae':\n",
    "    mae = mean_absolute_error(y_test.reshape(-1, 1), xgb.predict(X_test))\n",
    "  print(\"\\nThe mean absolute error (MAE) on test set: {:.4f}\".format(mae))\n",
    "  return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j8EffFEiwQ9s",
   "metadata": {
    "id": "j8EffFEiwQ9s"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# this function plots the true test values against predicted values\n",
    "def plot_results(model):\n",
    "  pred = model.predict(X_test)\n",
    "  mae = np.round(mean_absolute_error(y_test, pred), 3)\n",
    "  r2 = np.round(r2_score(y_test, pred), 3)\n",
    "  # mse = np.round(mean_squared_error(y_test, pred), 3)\n",
    "\n",
    "  print('MAE {},  R2 {}'.format(mae, r2))\n",
    "\n",
    "  plt.figure(figsize=(7,7))\n",
    "  plt.scatter(y_test, pred, c='#3b5998', s=50)\n",
    "  p1 = max(max(pred), max(y_test))\n",
    "  p2 = min(min(pred), min(y_test))\n",
    "  plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "  plt.xlabel('True Values', fontsize=15)\n",
    "  plt.ylabel('Predictions', fontsize=15)\n",
    "  plt.axis('equal')\n",
    "  plt.title('MAE {},  R2 {}'.format(mae, r2), fontdict={'size':15})\n",
    "  # Adding text on the plot.\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lj-k-OlOsLgH",
   "metadata": {
    "id": "Lj-k-OlOsLgH"
   },
   "outputs": [],
   "source": [
    "# this function plots loss after each iteration on train and on test sets\n",
    "def plot_deviance(model, params=None):\n",
    "  test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
    "  for i, y_pred in enumerate(model.staged_predict(X_test)):\n",
    "      test_score[i] = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "  fig = plt.figure(figsize=(6, 6))\n",
    "  plt.subplot(1, 1, 1)\n",
    "  plt.title(\"Deviance\")\n",
    "  plt.plot(\n",
    "      np.arange(params[\"n_estimators\"]) + 1,\n",
    "      model.train_score_,\n",
    "      \"b-\",\n",
    "      label=\"Training Set Deviance\",\n",
    "  )\n",
    "  plt.plot(\n",
    "      np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    "  )\n",
    "  plt.legend(loc=\"upper right\")\n",
    "  plt.xlabel(\"Boosting Iterations\")\n",
    "  plt.ylabel(\"Deviance\")\n",
    "  fig.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TSKLLeOmscer",
   "metadata": {
    "id": "TSKLLeOmscer"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# this function plots importances usinf the impurity-based and permutation methods\n",
    "def plot_importances(model, var_names, return_permutation=True):\n",
    "  feature_importance = model.feature_importances_\n",
    "  sorted_idx1 = np.argsort(feature_importance)\n",
    "  pos = np.arange(sorted_idx1.shape[0]) + 0.5\n",
    "\n",
    "  fig_size = (12, (len(var_names)/100)*20,)\n",
    "  print('figsize: ', fig_size)\n",
    "  fig = plt.figure(figsize=fig_size)\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.barh(pos, feature_importance[sorted_idx1], align=\"center\")\n",
    "  plt.yticks(pos, np.array(var_names)[sorted_idx1])\n",
    "  plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "  result = permutation_importance(\n",
    "      model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    "  )\n",
    "  sorted_idx2 = result.importances_mean.argsort()\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.boxplot(\n",
    "      result.importances[sorted_idx2].T,\n",
    "      vert=False,\n",
    "      labels=np.array(var_names)[sorted_idx2],\n",
    "  )\n",
    "  plt.title(\"Permutation Importance (test set)\")\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  if return_permutation:\n",
    "    return np.array(var_names)[sorted_idx2]\n",
    "  else:\n",
    "    return np.array(var_names)[sorted_idx1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nH05CnrS4Z9x",
   "metadata": {
    "id": "nH05CnrS4Z9x"
   },
   "source": [
    "This function is taken from the *yellowbrick* visualization library source code, since the normal import yielded some errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dhyx7dU6ouqN",
   "metadata": {
    "id": "dhyx7dU6ouqN"
   },
   "outputs": [],
   "source": [
    "# yellowbrick.regressor.residuals\n",
    "# Visualize the residuals between predicted and actual data for regression problems\n",
    "#\n",
    "# Author:   Rebecca Bilbro\n",
    "# Author:   Benjamin Bengfort\n",
    "# Created:  Fri Jun 03 10:30:36 2016 -0700\n",
    "#\n",
    "# Copyright (C) 2016 The scikit-yb developers\n",
    "# For license information, see LICENSE.txt\n",
    "#\n",
    "# ID: residuals.py [7d3f5e6] benjamin@bengfort.com $\n",
    "\n",
    "\"\"\"\n",
    "Visualize the residuals between predicted and actual data for regression problems\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import probplot\n",
    "\n",
    "try:\n",
    "    # Only available in Matplotlib >= 2.0.2\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "except ImportError:\n",
    "    make_axes_locatable = None\n",
    "\n",
    "from yellowbrick.draw import manual_legend\n",
    "from yellowbrick.utils.decorators import memoized\n",
    "from yellowbrick.style.palettes import LINE_COLOR\n",
    "from yellowbrick.exceptions import YellowbrickValueError\n",
    "from yellowbrick.regressor.base import RegressionScoreVisualizer\n",
    "\n",
    "class ResidualsPlot(RegressionScoreVisualizer):\n",
    "    \"\"\"\n",
    "    A residual plot shows the residuals on the vertical axis and the\n",
    "    independent variable on the horizontal axis.\n",
    "    If the points are randomly dispersed around the horizontal axis, a linear\n",
    "    regression model is appropriate for the data; otherwise, a non-linear\n",
    "    model is more appropriate.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : a Scikit-Learn regressor\n",
    "        Should be an instance of a regressor, otherwise will raise a\n",
    "        YellowbrickTypeError exception on instantiation.\n",
    "        If the estimator is not fitted, it is fit when the visualizer is fitted,\n",
    "        unless otherwise specified by ``is_fitted``.\n",
    "    ax : matplotlib Axes, default: None\n",
    "        The axes to plot the figure on. If None is passed in the current axes\n",
    "        will be used (or generated if required).\n",
    "    hist : {True, False, None, 'density', 'frequency'}, default: True\n",
    "        Draw a histogram showing the distribution of the residuals on the\n",
    "        right side of the figure. Requires Matplotlib >= 2.0.2.\n",
    "        If set to 'density', the probability density function will be plotted.\n",
    "        If set to True or 'frequency' then the frequency will be plotted.\n",
    "    qqplot : {True, False}, default: False\n",
    "        Draw a Q-Q plot on the right side of the figure, comparing the quantiles\n",
    "        of the residuals against quantiles of a standard normal distribution.\n",
    "        Q-Q plot and histogram of residuals can not be plotted simultaneously,\n",
    "        either `hist` or `qqplot` has to be set to False.\n",
    "    train_color : color, default: 'b'\n",
    "        Residuals for training data are ploted with this color but also\n",
    "        given an opacity of 0.5 to ensure that the test data residuals\n",
    "        are more visible. Can be any matplotlib color.\n",
    "    test_color : color, default: 'g'\n",
    "        Residuals for test data are plotted with this color. In order to\n",
    "        create generalizable models, reserved test data residuals are of\n",
    "        the most analytical interest, so these points are highlighted by\n",
    "        having full opacity. Can be any matplotlib color.\n",
    "    line_color : color, default: dark grey\n",
    "        Defines the color of the zero error line, can be any matplotlib color.\n",
    "    train_alpha : float, default: 0.75\n",
    "        Specify a transparency for traininig data, where 1 is completely opaque\n",
    "        and 0 is completely transparent. This property makes densely clustered\n",
    "        points more visible.\n",
    "    test_alpha : float, default: 0.75\n",
    "        Specify a transparency for test data, where 1 is completely opaque\n",
    "        and 0 is completely transparent. This property makes densely clustered\n",
    "        points more visible.\n",
    "    is_fitted : bool or str, default='auto'\n",
    "        Specify if the wrapped estimator is already fitted. If False, the estimator\n",
    "        will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
    "        modified. If 'auto' (default), a helper method will check if the estimator\n",
    "        is fitted before fitting it again.\n",
    "    kwargs : dict\n",
    "        Keyword arguments that are passed to the base class and may influence\n",
    "        the visualization as defined in other Visualizers.\n",
    "    Attributes\n",
    "    ----------\n",
    "    train_score_ : float\n",
    "        The R^2 score that specifies the goodness of fit of the underlying\n",
    "        regression model to the training data.\n",
    "    test_score_ : float\n",
    "        The R^2 score that specifies the goodness of fit of the underlying\n",
    "        regression model to the test data.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from yellowbrick.regressor import ResidualsPlot\n",
    "    >>> from sklearn.linear_model import Ridge\n",
    "    >>> model = ResidualsPlot(Ridge())\n",
    "    >>> model.fit(X_train, y_train)\n",
    "    >>> model.score(X_test, y_test)\n",
    "    >>> model.show()\n",
    "    Notes\n",
    "    -----\n",
    "    ResidualsPlot is a ScoreVisualizer, meaning that it wraps a model and\n",
    "    its primary entry point is the ``score()`` method.\n",
    "    The residuals histogram feature requires matplotlib 2.0.2 or greater.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        ax=None,\n",
    "        hist=True,\n",
    "        qqplot=False,\n",
    "        train_color=\"b\",\n",
    "        test_color=\"g\",\n",
    "        line_color=LINE_COLOR,\n",
    "        train_alpha=0.75,\n",
    "        test_alpha=0.75,\n",
    "        is_fitted=\"auto\",\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        # Initialize the visualizer base\n",
    "        super(ResidualsPlot, self).__init__(\n",
    "            estimator,\n",
    "            ax=ax,\n",
    "            is_fitted=is_fitted,\n",
    "            **kwargs)\n",
    "\n",
    "        # TODO: allow more scatter plot arguments for train and test points\n",
    "        # See #475 (RE: ScatterPlotMixin)\n",
    "        self.colors = {\n",
    "            \"train_point\": train_color,\n",
    "            \"test_point\": test_color,\n",
    "            \"line\": line_color,\n",
    "        }\n",
    "\n",
    "        self.hist = hist\n",
    "        if self.hist not in {True, \"density\", \"frequency\", None, False}:\n",
    "            raise YellowbrickValueError(\n",
    "                \"'{}' is an invalid argument for hist, use None, True, \"\n",
    "                \"False, 'density', or 'frequency'\".format(hist)\n",
    "            )\n",
    "\n",
    "        self.qqplot = qqplot\n",
    "        if self.qqplot not in {True, False}:\n",
    "            raise YellowbrickValueError(\n",
    "                \"'{}' is an invalid argument for qqplot, use True, \"\n",
    "                \" or False\".format(hist)\n",
    "            )\n",
    "\n",
    "        if self.hist in {True, \"density\", \"frequency\"} and self.qqplot in {True}:\n",
    "            raise YellowbrickValueError(\n",
    "                \"Set either hist or qqplot to False, can not plot \"\n",
    "                \"both of them simultaneously.\"\n",
    "            )\n",
    "\n",
    "        if self.hist in {True, \"density\", \"frequency\"}:\n",
    "            self.hax  # If hist is True, test the version availability\n",
    "\n",
    "        if self.qqplot in {True}:\n",
    "            self.qqax  # If qqplot is True, test the version availability\n",
    "\n",
    "        # Store labels and colors for the legend ordered by call\n",
    "        self._labels, self._colors = [], []\n",
    "\n",
    "        self.alphas = {\"train_point\": train_alpha, \"test_point\": test_alpha}\n",
    "\n",
    "    @memoized\n",
    "    def hax(self):\n",
    "        \"\"\"\n",
    "        Returns the histogram axes, creating it only on demand.\n",
    "        \"\"\"\n",
    "        if make_axes_locatable is None:\n",
    "            raise YellowbrickValueError(\n",
    "                (\n",
    "                    \"residuals histogram requires matplotlib 2.0.2 or greater \"\n",
    "                    \"please upgrade matplotlib or set hist=False on the visualizer\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        divider = make_axes_locatable(self.ax)\n",
    "\n",
    "        hax = divider.append_axes(\"right\", size=1, pad=0.1, sharey=self.ax)\n",
    "        hax.yaxis.tick_right()\n",
    "        hax.grid(False, axis=\"x\")\n",
    "\n",
    "        return hax\n",
    "\n",
    "    @memoized\n",
    "    def qqax(self):\n",
    "        \"\"\"\n",
    "        Returns the Q-Q plot axes, creating it only on demand.\n",
    "        \"\"\"\n",
    "        if make_axes_locatable is None:\n",
    "            raise YellowbrickValueError(\n",
    "                (\n",
    "                    \"residuals histogram requires matplotlib 2.0.2 or greater \"\n",
    "                    \"please upgrade matplotlib or set qqplot=False on the visualizer\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        divider = make_axes_locatable(self.ax)\n",
    "\n",
    "        qqax = divider.append_axes(\"right\", size=2, pad=0.25, sharey=self.ax)\n",
    "        qqax.yaxis.tick_right()\n",
    "\n",
    "        return qqax\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray or DataFrame of shape n x m\n",
    "            A matrix of n instances with m features\n",
    "        y : ndarray or Series of length n\n",
    "            An array or series of target values\n",
    "        kwargs: keyword arguments passed to Scikit-Learn API.\n",
    "        Returns\n",
    "        -------\n",
    "        self : ResidualsPlot\n",
    "            The visualizer instance\n",
    "        \"\"\"\n",
    "        # fit the underlying model to the data\n",
    "        super(ResidualsPlot, self).fit(X, y, **kwargs)\n",
    "        self.score(X, y, train=True)\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y=None, train=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Generates predicted target values using the Scikit-Learn\n",
    "        estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            X (also X_test) are the dependent variables of test set to predict\n",
    "        y : array-like\n",
    "            y (also y_test) is the independent actual variables to score against\n",
    "        train : boolean\n",
    "            If False, `score` assumes that the residual points being plotted\n",
    "            are from the test data; if True, `score` assumes the residuals\n",
    "            are the train data.\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            The score of the underlying estimator, usually the R-squared score\n",
    "            for regression estimators.\n",
    "        \"\"\"\n",
    "        # Do not call super in order to differentiate train and test scores.\n",
    "        score = self.estimator.score(X, y, **kwargs)\n",
    "        if train:\n",
    "            self.train_score_ = score\n",
    "        else:\n",
    "            self.test_score_ = score\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "        residuals = y_pred - y\n",
    "        self.draw(y_pred, residuals, train=train)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def draw(self, y_pred, residuals, train=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Draw the residuals against the predicted value for the specified split.\n",
    "        It is best to draw the training split first, then the test split so\n",
    "        that the test split (usually smaller) is above the training split;\n",
    "        particularly if the histogram is turned on.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : ndarray or Series of length n\n",
    "            An array or series of predicted target values\n",
    "        residuals : ndarray or Series of length n\n",
    "            An array or series of the difference between the predicted and the\n",
    "            target values\n",
    "        train : boolean, default: False\n",
    "            If False, `draw` assumes that the residual points being plotted\n",
    "            are from the test data; if True, `draw` assumes the residuals\n",
    "            are the train data.\n",
    "        Returns\n",
    "        -------\n",
    "        ax : matplotlib Axes\n",
    "            The axis with the plotted figure\n",
    "        \"\"\"\n",
    "\n",
    "        if train:\n",
    "            color = self.colors[\"train_point\"]\n",
    "            label = \"Train $R^2 = {:0.3f}$\".format(self.train_score_)\n",
    "            alpha = self.alphas[\"train_point\"]\n",
    "        else:\n",
    "            color = self.colors[\"test_point\"]\n",
    "            label = \"Test $R^2 = {:0.3f}$\".format(self.test_score_)\n",
    "            alpha = self.alphas[\"test_point\"]\n",
    "\n",
    "        # Update the legend information\n",
    "        self._labels.append(label)\n",
    "        self._colors.append(color)\n",
    "\n",
    "        # Draw the residuals scatter plot\n",
    "        self.ax.scatter(y_pred, residuals, c=color, alpha=alpha, label=label)\n",
    "\n",
    "        # Add residuals histogram\n",
    "        if self.hist in {True, \"frequency\"}:\n",
    "            self.hax.hist(residuals, bins=50, orientation=\"horizontal\", color=color)\n",
    "        elif self.hist == \"density\":\n",
    "            self.hax.hist(\n",
    "                residuals, bins=50, orientation=\"horizontal\", density=True, color=color\n",
    "            )\n",
    "\n",
    "        # Add residuals histogram\n",
    "        if self.qqplot in {True}:\n",
    "            osm, osr = probplot(residuals, dist=\"norm\", fit=False)\n",
    "\n",
    "            self.qqax.scatter(osm, osr, c=color, alpha=alpha, label=label)\n",
    "\n",
    "        # Ensure the current axes is always the main residuals axes\n",
    "        plt.sca(self.ax)\n",
    "        return self.ax\n",
    "\n",
    "    def finalize(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Prepares the plot for rendering by adding a title, legend, and axis labels.\n",
    "        Also draws a line at the zero residuals to show the baseline.\n",
    "        Parameters\n",
    "        ----------\n",
    "        kwargs: generic keyword arguments.\n",
    "        Notes\n",
    "        -----\n",
    "        Generally this method is called from show and not directly by the user.\n",
    "        \"\"\"\n",
    "        # Add the title to the plot\n",
    "        self.set_title(\"Residuals for {} Model\".format(self.name))\n",
    "\n",
    "        # Set the legend with full opacity patches using manual legend\n",
    "        manual_legend(self, self._labels, self._colors, loc=\"best\", frameon=True)\n",
    "\n",
    "        # Create a full line across the figure at zero error.\n",
    "        self.ax.axhline(y=0, c=self.colors[\"line\"])\n",
    "\n",
    "        # Set the axes labels\n",
    "        self.ax.set_ylabel(\"Residuals\")\n",
    "        self.ax.set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        # Finalize the histogram axes\n",
    "        if self.hist:\n",
    "            self.hax.axhline(y=0, c=self.colors[\"line\"])\n",
    "            self.hax.set_xlabel(\"Distribution\")\n",
    "\n",
    "        # Finalize the histogram axes\n",
    "        if self.qqplot:\n",
    "            self.qqax.set_title(\"Q-Q plot\")\n",
    "            self.qqax.set_xlabel(\"Theoretical quantiles\")\n",
    "            self.qqax.set_ylabel(\"Observed quantiles\")\n",
    "            \n",
    "def residuals_plot(\n",
    "    estimator,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    ax=None,\n",
    "    hist=True,\n",
    "    qqplot=False,\n",
    "    train_color=\"b\",\n",
    "    test_color=\"g\",\n",
    "    line_color=LINE_COLOR,\n",
    "    train_alpha=0.75,\n",
    "    test_alpha=0.75,\n",
    "    is_fitted=\"auto\",\n",
    "    show=True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"ResidualsPlot quick method:\n",
    "    A residual plot shows the residuals on the vertical axis and the\n",
    "    independent variable on the horizontal axis.\n",
    "    If the points are randomly dispersed around the horizontal axis, a linear\n",
    "    regression model is appropriate for the data; otherwise, a non-linear\n",
    "    model is more appropriate.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : a Scikit-Learn regressor\n",
    "        Should be an instance of a regressor, otherwise will raise a\n",
    "        YellowbrickTypeError exception on instantiation.\n",
    "        If the estimator is not fitted, it is fit when the visualizer is fitted,\n",
    "        unless otherwise specified by ``is_fitted``.\n",
    "    X_train : ndarray or DataFrame of shape n x m\n",
    "        A feature array of n instances with m features the model is trained on.\n",
    "        Used to fit the visualizer and also to score the visualizer if test splits are\n",
    "        not directly specified.\n",
    "    y_train : ndarray or Series of length n\n",
    "        An array or series of target or class values. Used to fit the visualizer and\n",
    "        also to score the visualizer if test splits are not specified.\n",
    "    X_test : ndarray or DataFrame of shape n x m, default: None\n",
    "        An optional feature array of n instances with m features that the model\n",
    "        is scored on if specified, using X_train as the training data.\n",
    "    y_test : ndarray or Series of length n, default: None\n",
    "        An optional array or series of target or class values that serve as actual\n",
    "        labels for X_test for scoring purposes.\n",
    "    ax : matplotlib Axes, default: None\n",
    "        The axes to plot the figure on. If None is passed in the current axes\n",
    "        will be used (or generated if required).\n",
    "    hist : {True, False, None, 'density', 'frequency'}, default: True\n",
    "        Draw a histogram showing the distribution of the residuals on the\n",
    "        right side of the figure. Requires Matplotlib >= 2.0.2.\n",
    "        If set to 'density', the probability density function will be plotted.\n",
    "        If set to True or 'frequency' then the frequency will be plotted.\n",
    "    qqplot : {True, False}, default: False\n",
    "        Draw a Q-Q plot on the right side of the figure, comparing the quantiles\n",
    "        of the residuals against quantiles of a standard normal distribution.\n",
    "        Q-Q plot and histogram of residuals can not be plotted simultaneously,\n",
    "        either `hist` or `qqplot` has to be set to False.\n",
    "    train_color : color, default: 'b'\n",
    "        Residuals for training data are ploted with this color but also\n",
    "        given an opacity of 0.5 to ensure that the test data residuals\n",
    "        are more visible. Can be any matplotlib color.\n",
    "    test_color : color, default: 'g'\n",
    "        Residuals for test data are plotted with this color. In order to\n",
    "        create generalizable models, reserved test data residuals are of\n",
    "        the most analytical interest, so these points are highlighted by\n",
    "        having full opacity. Can be any matplotlib color.\n",
    "    line_color : color, default: dark grey\n",
    "        Defines the color of the zero error line, can be any matplotlib color.\n",
    "    train_alpha : float, default: 0.75\n",
    "        Specify a transparency for traininig data, where 1 is completely opaque\n",
    "        and 0 is completely transparent. This property makes densely clustered\n",
    "        points more visible.\n",
    "    test_alpha : float, default: 0.75\n",
    "        Specify a transparency for test data, where 1 is completely opaque\n",
    "        and 0 is completely transparent. This property makes densely clustered\n",
    "        points more visible.\n",
    "    is_fitted : bool or str, default='auto'\n",
    "        Specify if the wrapped estimator is already fitted. If False, the estimator\n",
    "        will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
    "        modified. If 'auto' (default), a helper method will check if the estimator\n",
    "        is fitted before fitting it again.\n",
    "    show: bool, default: True\n",
    "        If True, calls ``show()``, which in turn calls ``plt.show()`` however you cannot\n",
    "        call ``plt.savefig`` from this signature, nor ``clear_figure``. If False, simply\n",
    "        calls ``finalize()``\n",
    "    kwargs : dict\n",
    "        Keyword arguments that are passed to the base class and may influence\n",
    "        the visualization as defined in other Visualizers.\n",
    "    Returns\n",
    "    -------\n",
    "    viz : ResidualsPlot\n",
    "        Returns the fitted ResidualsPlot that created the figure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the visualizer\n",
    "    viz = ResidualsPlot(\n",
    "        estimator=estimator,\n",
    "        ax=ax,\n",
    "        hist=hist,\n",
    "        qqplot=qqplot,\n",
    "        train_color=train_color,\n",
    "        test_color=test_color,\n",
    "        line_color=line_color,\n",
    "        train_alpha=train_alpha,\n",
    "        test_alpha=test_alpha,\n",
    "        is_fitted=is_fitted,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Fit the visualizer\n",
    "    viz.fit(X_train, y_train)\n",
    "\n",
    "    # Score the visualizer\n",
    "    if X_test is not None and y_test is not None:\n",
    "        viz.score(X_test, y_test)\n",
    "    elif X_test is not None or y_test is not None:\n",
    "        raise YellowbrickValueError(\n",
    "            \"both X_test and y_test are required if one is specified\"\n",
    "        )\n",
    "    else:\n",
    "        viz.score(X_train, y_train)\n",
    "\n",
    "    # Draw the final visualization\n",
    "    if show:\n",
    "        viz.show()\n",
    "    else:\n",
    "        viz.finalize()\n",
    "\n",
    "    # Return the visualizer\n",
    "    return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Vp3bD0zeCE4K",
   "metadata": {
    "id": "Vp3bD0zeCE4K"
   },
   "source": [
    "#### Model fit and evaluation (& feature importance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "-bY1s9K-77PY",
   "metadata": {
    "id": "-bY1s9K-77PY"
   },
   "source": [
    "We will run each model training and evaluation 5 times with random states 42, 43, 44, 45, 46 to get more trustworthy model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "IcDQ01ndLwSu",
   "metadata": {
    "id": "IcDQ01ndLwSu"
   },
   "source": [
    "Model with all 80 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WBYoH_vzBX98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBYoH_vzBX98",
    "outputId": "0dab7ad9-430f-4ead-9645-9b150250c9d3"
   },
   "outputs": [],
   "source": [
    "# set the parameters for the model\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"loss\": \"absolute_error\",\n",
    "    \"random_state\":46\n",
    "}\n",
    "\n",
    "# fit the model and see the results\n",
    "(X_train, X_test, y_train, y_test), var_names = split_data(feature_matrix, var_names=None, test_size=0.2, random_seed=42)\n",
    "model = fit_xgb(X_train, X_test, y_train, y_test, params=params, metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NWMrQAFrChnb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "NWMrQAFrChnb",
    "outputId": "43919c16-2028-40fa-cd18-e5802c375307"
   },
   "outputs": [],
   "source": [
    "plot_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ufr8ftE4CjB2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "ufr8ftE4CjB2",
    "outputId": "8559f1db-1873-4dd2-ae57-fe88c52313c4"
   },
   "outputs": [],
   "source": [
    "plot_deviance(model, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bR5ub-ADBSy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1bR5ub-ADBSy",
    "outputId": "60feb174-552f-4763-a18c-9737fdc85575"
   },
   "outputs": [],
   "source": [
    "importances = plot_importances(model, var_names, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Ipw8vVKJL2nK",
   "metadata": {
    "id": "Ipw8vVKJL2nK"
   },
   "source": [
    "Model with **40** the most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CiYlcaf05JLN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CiYlcaf05JLN",
    "outputId": "9124ab50-e037-45fe-a28f-a3e383198f44"
   },
   "outputs": [],
   "source": [
    "# choose the most important features to train a new model\n",
    "important_features = list(importances[-40:])\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FWOAn5CqJWdk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWOAn5CqJWdk",
    "outputId": "7378492f-9829-4c61-d78e-6b388b50047f"
   },
   "outputs": [],
   "source": [
    "# do training again with selected features\n",
    "# set the parameters for the model\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"loss\": \"absolute_error\",\n",
    "    \"random_state\":46\n",
    "}\n",
    "\n",
    "# fit the model and see the results\n",
    "(X_train, X_test, y_train, y_test), var_names = split_data(feature_matrix, var_names=important_features, test_size=0.2, random_seed=42)\n",
    "model_selected_features = fit_xgb(X_train, X_test, y_train, y_test, params=params, metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OQgcoXUyJla6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "OQgcoXUyJla6",
    "outputId": "99bcecec-c238-4ecd-b3e6-fb0f0ab9f102"
   },
   "outputs": [],
   "source": [
    "plot_results(model_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHnO-vOCJ9I3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "vHnO-vOCJ9I3",
    "outputId": "b6633481-d1af-42a9-bcf5-88f849210d5c"
   },
   "outputs": [],
   "source": [
    "plot_deviance(model_selected_features, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YR2QqnYKJ9eW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "YR2QqnYKJ9eW",
    "outputId": "15b57694-0d5f-4067-f3b5-41b3b6c92afa"
   },
   "outputs": [],
   "source": [
    "importances = plot_importances(model_selected_features, var_names, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "D_36AEPNNm9Z",
   "metadata": {
    "id": "D_36AEPNNm9Z"
   },
   "source": [
    "Model with **30** the most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cDsZ10dNo9z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cDsZ10dNo9z",
    "outputId": "f782a8cf-7c34-4ab2-c184-5a0bc4e4f191"
   },
   "outputs": [],
   "source": [
    "# choose the most important features to train a new model\n",
    "important_features = list(importances[-30:])\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pcgXL1CZNo7t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcgXL1CZNo7t",
    "outputId": "c81e1a10-caed-416f-ba75-59d852c829b1"
   },
   "outputs": [],
   "source": [
    "# do training again with selected features\n",
    "# set the parameters for the model\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"loss\": \"absolute_error\",\n",
    "    \"random_state\":46\n",
    "}\n",
    "\n",
    "# fit the model and see the results\n",
    "(X_train, X_test, y_train, y_test), var_names = split_data(feature_matrix, var_names=important_features, test_size=0.2, random_seed=42)\n",
    "model_selected_features = fit_xgb(X_train, X_test, y_train, y_test, params=params, metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xY3yptuzNo2V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "xY3yptuzNo2V",
    "outputId": "425eaaf8-f1a3-472d-e035-97d2e4da18fa"
   },
   "outputs": [],
   "source": [
    "plot_results(model_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RD_ubdXKNv3U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "RD_ubdXKNv3U",
    "outputId": "2af2274a-35fd-4191-da5e-0c48688fc1fa"
   },
   "outputs": [],
   "source": [
    "plot_deviance(model_selected_features, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1YgkCehJN0PI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "1YgkCehJN0PI",
    "outputId": "f35fe506-d814-42c5-d974-559c1bc0d54f"
   },
   "outputs": [],
   "source": [
    "importances = plot_importances(model_selected_features, var_names, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "TPEWgA5rZQbg",
   "metadata": {
    "id": "TPEWgA5rZQbg"
   },
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pWA9jZrAfkfq",
   "metadata": {
    "id": "pWA9jZrAfkfq"
   },
   "source": [
    "In the model training we use **Mean Absolute Error (MAE)**, because of two main factors:\n",
    "- since it is a regression problem, and MAE directly measures errors between predicted and true values and shows the mean of it;\n",
    "- because target variables values range between 0.0 and 1.0, therefore utilizing other error metrics, such as Mean Squared Error (MSE) will yield extremely small error values.\n",
    "\n",
    "\n",
    "In addition, we use the **R-squared** metric which measures the proportion of variance in the target variable that can be explained by the independent variables (predictors).\n",
    "\n",
    "---\n",
    "\n",
    "In the real world scenario one useful approach would be to define some classes to explain the target variable. With that in mind, we will convert the continuous target variable values into **three classes**:\n",
    "- **low risk** of high rates of adverse health outcomes in a county, denoted by 0\n",
    "- **moderate risk** of high rates of adverse health outcomes in a county, denoted by 1\n",
    "- **high risk** of high rates of adverse health outcomes in a county, denoted by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-bABOuBGZQ2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bABOuBGZQ2b",
    "outputId": "0f4d51b9-a9fb-4314-8096-80da0745edcc"
   },
   "outputs": [],
   "source": [
    "# get model predictions\n",
    "y_pred = model_selected_features.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "# convert direct values into three classes\n",
    "y_pred_cls = [0 if x<0.3 else 1 if x<0.6 else 2 for x in y_pred]\n",
    "y_true_cls = [0 if x<0.3 else 1 if x<0.6 else 2 for x in y_true]\n",
    "\n",
    "print('number of class 0 samples:', y_true_cls.count(0))\n",
    "print('number of class 1 samples:', y_true_cls.count(1))\n",
    "print('number of class 2 samples:', y_true_cls.count(2))\n",
    "print('total: ', len(y_pred_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2RXBDKp7ZxT_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RXBDKp7ZxT_",
    "outputId": "9cb0b86e-6df2-4024-a6e9-2068f138715b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true_cls, y_pred_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Obibw4FaRxc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "2Obibw4FaRxc",
    "outputId": "5d7610b3-63d7-45f7-e28e-de3091bd1732"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Creating  a confusion matrix,which compares the y_test and y_pred\n",
    "cm = confusion_matrix(y_true_cls, y_pred_cls, labels=[0,1,2])\n",
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['low risk','moderate risk','high risk'], \n",
    "                     columns = ['low risk','moderate risk','high risk'])\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True, cmap='BuPu', vmin=0, vmax=100, fmt='g')\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.ylabel('Actal Values', fontsize=12)\n",
    "plt.xlabel('Predicted Values', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Avg3Pnu2poJ-",
   "metadata": {
    "id": "Avg3Pnu2poJ-"
   },
   "source": [
    "The model was able to identify **majority of samples correctly**, with the highest F1 scores for moderate risk samples, since it is the most numerous class.\n",
    "\n",
    "The model overpredicted 11 low risk samples as at moderate risk. 8 samples belonging at risk class were misclassified as at low or high risk. Finally, 8 samples, belonging to high risk class were classified as at moderate risk. \n",
    "\n",
    "No samples at low risk class were classified as at  high risk, and **no samples  at high risk  were classified as at low risk**.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2vvF1OyUOIgI",
   "metadata": {
    "id": "2vvF1OyUOIgI"
   },
   "source": [
    "#### Evaluation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xL_dZ5WyAflx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xL_dZ5WyAflx",
    "outputId": "f72f0958-25a4-4bea-831a-723e5ee9cb51"
   },
   "outputs": [],
   "source": [
    "# performace for each of 5 training rounds\n",
    "performance_all = {'mae':[0.021, 0.02, 0.021, 0.021, 0.021], 'r2':[0.908, 0.924, 0.911, 0.907, 0.912]}\n",
    "performance_40 = {'mae':[0.02, 0.02, 0.02, 0.021, 0.021], 'r2':[0.915, 0.917, 0.919, 0.912, 0.916]}\n",
    "performance_30 = {'mae':[0.02, 0.02, 0.02, 0.021, 0.02], 'r2':[0.924, 0.923, 0.93, 0.914, 0.925]}\n",
    "\n",
    "# get the mean and std for each model\n",
    "mae_all_mean = np.round(np.mean(performance_all['mae']), 3)\n",
    "mae_all_std = np.round(np.std(performance_all['mae']), 4)\n",
    "mae_40_mean = np.round(np.mean(performance_40['mae']),3)\n",
    "mae_40_std = np.round(np.std(performance_40['mae']),4)\n",
    "mae_30_mean = np.round(np.mean(performance_30['mae']),3)\n",
    "mae_30_std = np.round(np.std(performance_30['mae']),4)\n",
    "\n",
    "r2_all_mean = np.round(np.mean(performance_all['r2']), 3)\n",
    "r2_all_std = np.round(np.std(performance_all['r2']), 4)\n",
    "r2_40_mean = np.round(np.mean(performance_40['r2']),3)\n",
    "r2_40_std = np.round(np.std(performance_40['r2']),4)\n",
    "r2_30_mean = np.round(np.mean(performance_30['r2']),3)\n",
    "r2_30_std = np.round(np.std(performance_30['r2']),4)\n",
    "\n",
    "print('All features model: MAE {}({}), R2 {}({})'.format(mae_all_mean, mae_all_std, r2_all_mean, r2_all_std))\n",
    "print('40 features model: MAE {}({}), R2 {}({})'.format(mae_40_mean, mae_40_std, r2_40_mean, r2_40_std))\n",
    "print('30 features model: MAE {}({}), R2 {}({})'.format(mae_30_mean, mae_30_std, r2_30_mean, r2_30_std))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "GKqJhV3HN6QV",
   "metadata": {
    "id": "GKqJhV3HN6QV"
   },
   "source": [
    "After training each of the three models with different set of predictors, we got the following results:\n",
    "\n",
    "- all 80 predictors: **MAE 0.021 (std 0.0004),  R2 0.912 (std 0.0061)**\n",
    "- 40 the most important predictors: **MAE 0.020 (std 0.0005),  R2 0.916 (std 0.0023)**\n",
    "- 30 the most important predictors: **MAE 0.020 (std 0.0004),  R2 0.923 (std 0.0052)**\n",
    "\n",
    "The best results yielded the model trained on 30 the most important predictor variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Ft43YNZVRrvI",
   "metadata": {
    "id": "Ft43YNZVRrvI"
   },
   "source": [
    "The most important features are health risk behavior rates such as \"*currently smoking\", \"low physical activity\", \"sleep less than 7 hours\", \"binge drinking\"*, as well as preventive measures rates such as \"*taking blood pressure medicines\", \"cholesterol screening\", \"routine checkup visits\", \"cervical cancer screening\", \"dentist visits*\".\n",
    "\n",
    "\n",
    "Other important predictors are related to **social vulnerability status**, such as percent of people with disabilities, household income, unemployment rate, poverty, limited english, and education level.\n",
    "\n",
    "\n",
    "In addition, **demographic information** such as percent of people of asian race, elderly people of two or more races, percent of young people of black or african american race, elderly and young american indian and alaska native people, as well as percent of native hawaiian people in the county.\n",
    "\n",
    "One interesting observation is that model put high importance into percentage of **white race people in elderly** and people **between 20 and 39 years old**. This may be the result of the prevalence of white race population across majority of US counties. Most probably, the model  simply took into consideration this feature because it yields the most information about percent of elderly people in a county. It would be informative to see which predictor the model would choose if we had percentage of each age group regardless of race in the feature set.\n",
    "\n",
    "Another observation regarding feature importance, is that the model put some importance into features related to average annual sunshine by state, such as\n",
    "- **% of sun**: the percentage of time between sunrise and sunset that sunshine reaches the ground;\n",
    "- **Total Hours** is the average number of sunny hours a place normally has in a year;\n",
    "- **Clear Days** is the average number of days annually when cloud covers at most 30 percent of the sky during daylight hours.\n",
    "\n",
    "\n",
    "These three variables are correlated, meaning that keeping only one of them would probably yield similar results. In addition, they are state-level variables, meaning that they might bring geographical information to the model, and it would be informative to substitute them with one 'state' variable and to see how it will affect the model's performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "-FMQd5SZUEM2",
   "metadata": {
    "id": "-FMQd5SZUEM2"
   },
   "source": [
    "Key to race coding map: \n",
    "- ba - black of african alone\n",
    "- ia - american indian and alaska native alone \n",
    "- aa - asian alone\n",
    "- na - native hawaiian and other pacific islander alone\n",
    "- wa - white alone\n",
    "- tom - two or more races \n",
    "\n",
    "Key to age group map:\n",
    "- age group 0: total\n",
    "- age group 1: 0-19 \n",
    "- age group 2: 20-39\n",
    "- age group 3: 40-64\n",
    "- age group 0: 65+"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "AAukQDaA7o_C",
   "metadata": {
    "id": "AAukQDaA7o_C"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*Maslenkova Svetlana, March 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BHNHHkUZEEu-",
   "metadata": {
    "id": "BHNHHkUZEEu-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ghamut_test_env",
   "language": "python",
   "name": "ghamut_test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
